{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Current PyTorch Version: 1.0.0\n",
      "Current CuDNN Version: 7102\n",
      "Current Cuda Version: 8.0.61\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# coding: utf-8\n",
    "import os\n",
    "os.environ[\"CUDA_DEVICE_ORDER\"]=\"PCI_BUS_ID\"   # see issue #152\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"1\"         # 1 is can change to 0-3\n",
    "\n",
    "\"\"\"\n",
    "Train a model on Yelp Review.\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "from datetime import datetime\n",
    "import time\n",
    "import numpy as np\n",
    "import random\n",
    "import argparse\n",
    "from shutil import copyfile\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "from global_random_seed import RANDOM_SEED\n",
    "\n",
    "# this doesn't seem to work any better than what we have\n",
    "from torch.optim.lr_scheduler import ReduceLROnPlateau\n",
    "from data.loader import DataLoader, KnowledgeLoader\n",
    "from model.model import SA_Model\n",
    "from utils import scorer, constant, helper\n",
    "from utils.vocab import Vocab\n",
    "\n",
    "# print out what PyTorch Version we are using\n",
    "print()\n",
    "print(\"Current PyTorch Version:\", torch.__version__)\n",
    "print(\"Current CuDNN Version:\", torch.backends.cudnn.version())\n",
    "print(\"Current Cuda Version:\", torch.version.cuda)\n",
    "print()\n",
    "\n",
    "# do this if you run this code in a Notebook\n",
    "import sys; sys.argv=['']; del sys  # this has to be done if argparse is used in the notebook\n",
    "\n",
    "\n",
    "parser = argparse.ArgumentParser()\n",
    "\n",
    "parser.add_argument('--data_dir', type=str, default='dataset/yelp_review_small')\n",
    "parser.add_argument('--vocab_dir', type=str, default='dataset/yelp_review_small')\n",
    "parser.add_argument('--emb_dim', type=int, default=300, help='Word embedding dimension.')\n",
    "parser.add_argument('--hidden_dim', type=int, default=360, help='RNN hidden state size.')       # 200 original\n",
    "parser.add_argument('--hidden_self', type=int, default=130,\n",
    "                    help='Hidden size for self-attention.')         # n_model*2 in the paper  # used to be 720\n",
    "parser.add_argument('--num_layers', type=int, default=2, help='Num of lstm layers.')\n",
    "parser.add_argument('--dense_dim', type=int, default=200, help='Dense layer size before Softmax.') \n",
    "\n",
    "# encoder layers\n",
    "parser.add_argument('--n_head', type=int, default=3, help='Number of self-attention heads.')\n",
    "parser.add_argument('--num_layers_encoder', type=int, default=1, help='Num of self-attention encoders.')\n",
    "parser.add_argument('--dropout', type=float, default=0.4, help='Input and attn dropout rate.')            # 0.1 original\n",
    "parser.add_argument('--scaled_dropout', type=float, default=0.1, help='Input and scaled dropout rate.')   # 0.1 original\n",
    "parser.add_argument('--temper_value', type=float, default=0.5, help='Temper value for Scaled Attention.') # 0.5 original\n",
    "\n",
    "parser.add_argument('--word_dropout', type=float, default=0.06,                                      # 0.04\n",
    "    help='The rate at which randomly set a word to UNK.')\n",
    "parser.add_argument('--lstm_dropout', type=float, default=0.5, help='Input and RNN dropout rate.')\n",
    "parser.add_argument('--topn', type=int, default=1e10, help='Only finetune top N embeddings.')\n",
    "parser.add_argument('--lower', dest='lower', action='store_true', help='Lowercase all words.',\n",
    "                   default=False)\n",
    "parser.add_argument('--no-lower', dest='lower', action='store_false')\n",
    "parser.set_defaults(lower=False)\n",
    "parser.add_argument('--weight_no_rel', type=float, default=1.0, help='Weight for no_relation class.')\n",
    "parser.add_argument('--weight_rest', type=float, default=1.0, help='Weight for other classes.')\n",
    "parser.add_argument(\n",
    "    '--self-attn', dest='self_att', action='store_true', help='Use self-attention layer instead of LSTM.', default=True)\n",
    "# parser.add_argument('--no_self_att', dest='self_att', action='store_false',\n",
    "#     help='Use self-attention layer instead of LSTM.')\n",
    "parser.set_defaults(self_att=True)\n",
    "\n",
    "# batch norm\n",
    "parser.add_argument('--use_batch_norm', dest='use_batch_norm', action='store_true', \n",
    "    help='BatchNorm if true, else LayerNorm in self-attention.', default=False)\n",
    "parser.add_argument('--use_layer_norm', dest='use_batch_norm', action='store_false',\n",
    "    help='BatchNorm if true, else LayerNorm in self-attention.', default=True)\n",
    "parser.set_defaults(use_batch_norm=True)\n",
    "\n",
    "# dpa\n",
    "parser.add_argument('--diagonal_positional_attention', dest='diagonal_positional_attention', action='store_true',\n",
    "    help='Use diagonal attention positional encoding instead of sinusoidal position encoding.', default=False)\n",
    "parser.add_argument('--no_diagonal_positional_attention', dest='diagonal_positional_attention', action='store_false')\n",
    "parser.set_defaults(diagonal_positional_attention=False)\n",
    "parser.add_argument('--relative_pos_dim', type=int, default=50, help='relative position embedding dimension in self-attention.')\n",
    "\n",
    "# relative positional vectors\n",
    "parser.add_argument('--relative_positions', dest='relative_positions', action='store_true',\n",
    "    help='Use relative positions (with position binning) for subj/obj positional vectors.', default=True)\n",
    "parser.add_argument('--no_relative_positions', dest='relative_positions', action='store_false')\n",
    "parser.set_defaults(relative_positions=True)\n",
    "\n",
    "# how to use residual connections\n",
    "parser.add_argument('--new_residual', dest='new_residual', action='store_true', \n",
    "    help='Use a different residual connection than in usual self-attention.', default=True)\n",
    "parser.add_argument('--old_residual', dest='new_residual', action='store_false')\n",
    "parser.set_defaults(new_residual=True)\n",
    "\n",
    "# use positional attention from stanford paper\n",
    "parser.add_argument('--attn', dest='attn', action='store_true', help='Use attention layer.', default=\"true\")\n",
    "parser.add_argument('--no-attn', dest='attn', action='store_false')\n",
    "parser.set_defaults(attn=True)\n",
    "parser.add_argument('--attn_dim', type=int, default=200, help='Attention size.')                    # 200 original\n",
    "parser.add_argument('--pe_dim', type=int, default=30, help='Position encoding dimension.')\n",
    "\n",
    "parser.add_argument('--lr', type=float, default=0.1, help='Applies to SGD and Adagrad.')            # lr 1.0 orig\n",
    "parser.add_argument('--lr_decay', type=float, default=0.9)\n",
    "parser.add_argument('--decay_epoch', type=int, default=15, help='Start LR decay from this epoch.')\n",
    "\n",
    "parser.add_argument('--optim', type=str, default='sgd', help='sgd, asgd, adagrad, adam, nadam or adamax.')\n",
    "parser.add_argument('--num_epoch', type=int, default=70)\n",
    "parser.add_argument('--batch_size', type=int, default=50)\n",
    "parser.add_argument('--max_grad_norm', type=float, default=1.0, help='Gradient clipping.')\n",
    "\n",
    "# info for model saving\n",
    "parser.add_argument('--log_step', type=int, default=1000, help='Print log every k steps.')\n",
    "parser.add_argument('--log', type=str, default='logs.txt', help='Write training log to file.')\n",
    "parser.add_argument('--save_epoch', type=int, default=1, help='Save model checkpoints every k epochs.')\n",
    "parser.add_argument('--save_dir', type=str, default='./saved_models', help='Root dir for saving models.')\n",
    "\n",
    "parser.add_argument('--id', type=str, default='tmp_model',  # change model folder output\n",
    "    help='Model ID under which to save models.')\n",
    "\n",
    "parser.add_argument('--info', type=str, default='', help='Optional info for the experiment.')\n",
    "\n",
    "# We want to set random seed for all files\n",
    "# so instead set the random seed in the global_random_seed.py file\n",
    "parser.add_argument('--seed', type=int, default=1234)\n",
    "parser.add_argument('--cuda', type=bool, default=torch.cuda.is_available())\n",
    "parser.add_argument('--cpu', action='store_true', help='Ignore CUDA.')\n",
    "\n",
    "args = parser.parse_args()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# write the seed into a file and let it be read from there in all files\n",
    "with open('global_random_seed.py', 'w') as the_file:\n",
    "    the_file.write('RANDOM_SEED = '+str(args.seed))\n",
    "\n",
    "# improves speed of cuda, these are set to False by default due to high memory usage\n",
    "torch.backends.cudnn.fastest = True\n",
    "torch.backends.cudnn.benchmark = False\n",
    "# torch.set_num_threads(8)   # TODO: this doesn't seem to do anything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Vocab size 230902 loaded from file\n"
     ]
    }
   ],
   "source": [
    "# set top-level random seeds\n",
    "torch.manual_seed(args.seed)\n",
    "np.random.seed(args.seed)\n",
    "random.seed(args.seed)\n",
    "\n",
    "if args.cpu:\n",
    "    args.cuda = False\n",
    "elif args.cuda:\n",
    "    # force random seed for reproducibility\n",
    "    # also apply same seed to numpy in every file\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.cuda.manual_seed(args.seed)\n",
    "    torch.cuda.manual_seed_all(args.seed)\n",
    "\n",
    "# make opt\n",
    "opt = vars(args)\n",
    "# opt['num_class'] = len(constant.LABEL_TO_ID)\n",
    "\n",
    "# load vocab\n",
    "vocab_file = opt['vocab_dir'] + '/vocab.pkl'\n",
    "vocab = Vocab(vocab_file, load=True)\n",
    "\n",
    "# in some previous experiments we saw that lower vocab size can improve performance\n",
    "# but it was in a completely different project although on the same data\n",
    "# here it seems it's much harder to get this to work\n",
    "# uncomment the following line if this is solved:\n",
    "# new_vocab_size = 30000\n",
    "\n",
    "opt['vocab_size'] = vocab.size\n",
    "emb_file = opt['vocab_dir'] + '/embedding.npy'\n",
    "emb_matrix = np.load(emb_file)\n",
    "assert emb_matrix.shape[0] == vocab.size\n",
    "assert emb_matrix.shape[1] == opt['emb_dim']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# adjust parameters for experiments\n",
    "opt['num_class'] = 5\n",
    "opt['num_epoch'] =70\n",
    "opt['batch_size'] = 100\n",
    "opt['lr'] = 0.01\n",
    "opt['decay_epoch'] = 10\n",
    "# opt['lr_decay'] = 0.95\n",
    "# opt['num_layers'] = 1  # LSTM layers original 2\n",
    "\n",
    "# for transformer encoder\n",
    "opt['num_layers_encoder'] = 1\n",
    "opt['n_head'] = 6\n",
    "opt['diagonal_positional_attention'] = False\n",
    "opt['relative_pos_dim'] = 50\n",
    "opt['use_batch_norm'] = False\n",
    "opt[\"new_residual\"] = True\n",
    "# opt['hidden_self'] = 130   # default 130\n",
    "\n",
    "# for position-aware attention\n",
    "opt['pe_dim'] =30   # 30 original\n",
    "opt['attn_dim'] = 200  # 200 original\n",
    "\n",
    "opt['dense_dim'] = 100  # decision-level attn dim or linear dim before softmax. default:100\n",
    "opt['topn'] = 0  # 0:do not fine tune word embeddings, 21: fine tune entities masks and UNK_TOKEN token\n",
    "opt['lower'] = False\n",
    "\n",
    "opt['id'] = 'tmp_model'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from dataset/yelp_review_small with batch size 100...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 650000/650000 [00:35<00:00, 18354.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6500 batches created for dataset/yelp_review_small/train_processed.json\n"
     ]
    }
   ],
   "source": [
    "# load data\n",
    "print(\"Loading data from {} with batch size {}...\".format(opt['data_dir'], opt['batch_size']))\n",
    "train_batch = DataLoader(opt['data_dir'] + '/train_processed.json', opt['batch_size'], opt, vocab, evaluation=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_i = 16\n",
    "test_d = train_batch.data[0][test_i]   # fist batch, ith data\n",
    "\n",
    "# print('tokens: ', test_d[0], 'length:', len(test_d[0]))\n",
    "# print('pos: ', test_d[1])\n",
    "# print('ner: ', test_d[2])\n",
    "# print('entity markers: ', test_d[3])\n",
    "# print('subj_positions: ', test_d[4])\n",
    "# print('obj_positions: ', test_d[5])\n",
    "# # print('relative_positions: ', test_d[6], 'len:', len(test_d[6]))\n",
    "# print('inst_position: ', test_d[6])\n",
    "# print('relation: ', test_d[7])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_i = 2\n",
    "test_d_torch = train_batch[0]\n",
    "\n",
    "# print('tokens: ', test_d_torch[0][test_i], 'length:', len(test_d_torch[0][test_i]))\n",
    "# print('mask: ', test_d_torch[1][test_i])\n",
    "# print('pos: ', test_d_torch[2][test_i])\n",
    "# print('ner: ', test_d_torch[3][test_i])\n",
    "# print('deprel: ', test_d_torch[4][test_i])\n",
    "# print('subj_positions: ', test_d_torch[5][test_i])\n",
    "# print('obj_positions: ', test_d_torch[6][test_i])\n",
    "# print('relative_positions_dpa: ', test_d_torch[7][test_i], 'len:', len(test_d_torch[7][test_i]))\n",
    "# print('src_position: ', test_d_torch[8][test_i])\n",
    "# print('subj_type: ', test_d_torch[9][test_i])\n",
    "# print('obj_type: ', test_d_torch[10][test_i])\n",
    "# print('rels: ', test_d_torch[11][test_i])\n",
    "# print('orig_idx: ', test_d_torch[12][test_i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 50000/50000 [00:02<00:00, 24221.60it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000 batches created for dataset/yelp_review_small/test_processed.json\n",
      "Config saved to file ./saved_models/tmp_model/config.json\n",
      "Overwriting old vocab file at ./saved_models/tmp_model/vocab.pkl\n",
      "\n",
      "Running with the following configs:\n",
      "\tdata_dir : dataset/yelp_review_small\n",
      "\tvocab_dir : dataset/yelp_review_small\n",
      "\temb_dim : 300\n",
      "\tner_dim : 0\n",
      "\tpos_dim : 0\n",
      "\tentity_marker_dim : 0\n",
      "\thidden_dim : 360\n",
      "\thidden_self : 130\n",
      "\tquery_size_attn : 360\n",
      "\tnum_layers : 2\n",
      "\tner_dim_subj_obj : 0\n",
      "\tdense_dim : 100\n",
      "\tnum_layers_encoder : 1\n",
      "\tdropout : 0.4\n",
      "\tscaled_dropout : 0.1\n",
      "\ttemper_value : 0.5\n",
      "\tword_dropout : 0.06\n",
      "\tlstm_dropout : 0.5\n",
      "\ttopn : 0\n",
      "\tlower : False\n",
      "\tweight_no_rel : 1.0\n",
      "\tweight_rest : 1.0\n",
      "\tself_att : True\n",
      "\tself_att_and_rnn : False\n",
      "\tuse_lemmas : False\n",
      "\tpreload_lemmas : False\n",
      "\tobj_sub_pos : False\n",
      "\tuse_batch_norm : False\n",
      "\tdiagonal_positional_attention : False\n",
      "\trelative_pos_dim : 50\n",
      "\trelative_positions : True\n",
      "\tnew_residual : False\n",
      "\tn_head : 6\n",
      "\tn_head_CNN : 6\n",
      "\tattn : True\n",
      "\tattn_dim : 200\n",
      "\tpe_dim : 30\n",
      "\tlr : 0.01\n",
      "\tlr_decay : 0.9\n",
      "\tdecay_epoch : 10\n",
      "\toptim : sgd\n",
      "\tnum_epoch : 70\n",
      "\tbatch_size : 100\n",
      "\tmax_grad_norm : 1.0\n",
      "\tlog_step : 1000\n",
      "\tlog : logs.txt\n",
      "\tsave_epoch : 1\n",
      "\tsave_dir : ./saved_models\n",
      "\tid : tmp_model\n",
      "\tinfo : \n",
      "\tseed : 1234\n",
      "\tcuda : True\n",
      "\tcpu : False\n",
      "\tuse_knowledge : False\n",
      "\ttransformer_CNN : True\n",
      "\tvocab_size : 230902\n",
      "\tnum_class : 5\n",
      "\tnum_layers_transCNN : 3\n",
      "\tmodel_save_dir : ./saved_models/tmp_model\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "dev_batch = DataLoader(opt['data_dir'] + '/test_processed.json', opt['batch_size'], opt, vocab, evaluation=True)\n",
    "\n",
    "model_id = opt['id'] if len(opt['id']) > 1 else '0' + opt['id']\n",
    "model_save_dir = opt['save_dir'] + '/' + model_id\n",
    "opt['model_save_dir'] = model_save_dir\n",
    "helper.ensure_dir(model_save_dir, verbose=True)\n",
    "\n",
    "# save config\n",
    "helper.save_config(opt, model_save_dir + '/config.json', verbose=True)\n",
    "vocab.save(model_save_dir + '/vocab.pkl')\n",
    "file_logger = helper.FileLogger(\n",
    "    model_save_dir + '/' + opt['log'],\n",
    "    header=\"# epoch\\ttrain_loss\\tdev_loss\\tdev_p\\tdev_r\\tdev_f1\"\n",
    ")\n",
    "\n",
    "# print model info\n",
    "helper.print_config(opt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Self-attn input dim: 300\n",
      "Knowledge-attn input dim: 300\n",
      "Number of self-attn heads:  6\n",
      "d_v and d_k:  50.0\n",
      "Do not fine-tune word embedding layer.\n"
     ]
    }
   ],
   "source": [
    "# model\n",
    "model = SA_Model(opt, emb_matrix=emb_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "dev_f1_history = []\n",
    "current_lr = opt['lr']\n",
    "\n",
    "global_step = 0\n",
    "\n",
    "format_str = '{}: step {}/{} (epoch {}/{}), loss = {:.6f} ({:.3f} sec/batch), lr: {:.6f}'\n",
    "max_steps = len(train_batch) * opt['num_epoch']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-29 15:48:38.885525: step 1000/455000 (epoch 1/70), loss = 1.090372 (0.449 sec/batch), lr: 0.010000\n",
      "2019-09-29 15:56:08.656363: step 2000/455000 (epoch 1/70), loss = 1.156877 (0.476 sec/batch), lr: 0.010000\n",
      "2019-09-29 16:03:38.758173: step 3000/455000 (epoch 1/70), loss = 1.015465 (0.316 sec/batch), lr: 0.010000\n",
      "2019-09-29 16:11:04.470483: step 4000/455000 (epoch 1/70), loss = 0.990872 (0.568 sec/batch), lr: 0.010000\n",
      "2019-09-29 16:18:36.098254: step 5000/455000 (epoch 1/70), loss = 1.095273 (0.324 sec/batch), lr: 0.010000\n",
      "2019-09-29 16:26:09.206407: step 6000/455000 (epoch 1/70), loss = 0.884808 (0.440 sec/batch), lr: 0.010000\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.62      0.85      0.72     10000\n",
      "          1       0.51      0.45      0.48     10000\n",
      "          2       0.55      0.38      0.45     10000\n",
      "          3       0.52      0.43      0.47     10000\n",
      "          4       0.63      0.77      0.70     10000\n",
      "\n",
      "avg / total       0.57      0.58      0.56     50000\n",
      "\n",
      "accuracy: 0.577\n",
      "epoch 1: train_loss = 1.067202, dev_loss = 1.954509, dev_f1 = 0.5770\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_1.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-29 16:35:03.318091: step 7000/455000 (epoch 2/70), loss = 0.963486 (0.313 sec/batch), lr: 0.010000\n",
      "2019-09-29 16:42:32.340075: step 8000/455000 (epoch 2/70), loss = 0.850156 (0.407 sec/batch), lr: 0.010000\n",
      "2019-09-29 16:50:03.143270: step 9000/455000 (epoch 2/70), loss = 1.108567 (0.362 sec/batch), lr: 0.010000\n",
      "2019-09-29 16:57:31.830309: step 10000/455000 (epoch 2/70), loss = 0.859298 (0.443 sec/batch), lr: 0.010000\n",
      "2019-09-29 17:04:59.455392: step 11000/455000 (epoch 2/70), loss = 1.007898 (0.306 sec/batch), lr: 0.010000\n",
      "2019-09-29 17:12:31.762488: step 12000/455000 (epoch 2/70), loss = 0.920073 (0.560 sec/batch), lr: 0.010000\n",
      "2019-09-29 17:20:04.979779: step 13000/455000 (epoch 2/70), loss = 0.986684 (0.325 sec/batch), lr: 0.010000\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.86      0.74     10000\n",
      "          1       0.55      0.44      0.49     10000\n",
      "          2       0.57      0.44      0.50     10000\n",
      "          3       0.53      0.43      0.48     10000\n",
      "          4       0.63      0.81      0.71     10000\n",
      "\n",
      "avg / total       0.59      0.60      0.58     50000\n",
      "\n",
      "accuracy: 0.59698\n",
      "epoch 2: train_loss = 0.970979, dev_loss = 1.861597, dev_f1 = 0.5970\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_2.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-29 17:28:56.461062: step 14000/455000 (epoch 3/70), loss = 0.947831 (0.451 sec/batch), lr: 0.010000\n",
      "2019-09-29 17:36:26.733255: step 15000/455000 (epoch 3/70), loss = 1.005104 (0.479 sec/batch), lr: 0.010000\n",
      "2019-09-29 17:43:56.964698: step 16000/455000 (epoch 3/70), loss = 0.930863 (0.316 sec/batch), lr: 0.010000\n",
      "2019-09-29 17:51:22.857134: step 17000/455000 (epoch 3/70), loss = 0.802844 (0.570 sec/batch), lr: 0.010000\n",
      "2019-09-29 17:58:54.416326: step 18000/455000 (epoch 3/70), loss = 0.989589 (0.323 sec/batch), lr: 0.010000\n",
      "2019-09-29 18:06:28.096078: step 19000/455000 (epoch 3/70), loss = 0.747159 (0.443 sec/batch), lr: 0.010000\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.66      0.86      0.75     10000\n",
      "          1       0.56      0.48      0.51     10000\n",
      "          2       0.60      0.46      0.52     10000\n",
      "          3       0.56      0.44      0.49     10000\n",
      "          4       0.64      0.82      0.72     10000\n",
      "\n",
      "avg / total       0.60      0.61      0.60     50000\n",
      "\n",
      "accuracy: 0.61206\n",
      "epoch 3: train_loss = 0.924793, dev_loss = 1.833756, dev_f1 = 0.6121\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_3.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-29 18:15:22.780386: step 20000/455000 (epoch 4/70), loss = 0.878374 (0.310 sec/batch), lr: 0.010000\n",
      "2019-09-29 18:22:52.504881: step 21000/455000 (epoch 4/70), loss = 0.794227 (0.410 sec/batch), lr: 0.010000\n",
      "2019-09-29 18:30:23.853600: step 22000/455000 (epoch 4/70), loss = 0.973486 (0.362 sec/batch), lr: 0.010000\n",
      "2019-09-29 18:37:53.081509: step 23000/455000 (epoch 4/70), loss = 0.826774 (0.442 sec/batch), lr: 0.010000\n",
      "2019-09-29 18:45:21.049340: step 24000/455000 (epoch 4/70), loss = 0.906622 (0.304 sec/batch), lr: 0.010000\n",
      "2019-09-29 18:52:53.528455: step 25000/455000 (epoch 4/70), loss = 0.855800 (0.561 sec/batch), lr: 0.010000\n",
      "2019-09-29 19:00:26.681723: step 26000/455000 (epoch 4/70), loss = 0.839462 (0.326 sec/batch), lr: 0.010000\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.89      0.74     10000\n",
      "          1       0.56      0.46      0.51     10000\n",
      "          2       0.61      0.46      0.53     10000\n",
      "          3       0.58      0.44      0.50     10000\n",
      "          4       0.65      0.81      0.72     10000\n",
      "\n",
      "avg / total       0.61      0.61      0.60     50000\n",
      "\n",
      "accuracy: 0.6144\n",
      "epoch 4: train_loss = 0.895001, dev_loss = 1.841647, dev_f1 = 0.6144\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_4.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-29 19:09:17.892613: step 27000/455000 (epoch 5/70), loss = 0.905276 (0.450 sec/batch), lr: 0.010000\n",
      "2019-09-29 19:16:48.391068: step 28000/455000 (epoch 5/70), loss = 0.921342 (0.477 sec/batch), lr: 0.010000\n",
      "2019-09-29 19:24:18.755017: step 29000/455000 (epoch 5/70), loss = 0.865716 (0.315 sec/batch), lr: 0.010000\n",
      "2019-09-29 19:31:44.806383: step 30000/455000 (epoch 5/70), loss = 0.783493 (0.569 sec/batch), lr: 0.010000\n",
      "2019-09-29 19:39:16.701164: step 31000/455000 (epoch 5/70), loss = 0.986341 (0.326 sec/batch), lr: 0.010000\n",
      "2019-09-29 19:46:50.101268: step 32000/455000 (epoch 5/70), loss = 0.739152 (0.443 sec/batch), lr: 0.010000\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.64      0.90      0.74     10000\n",
      "          1       0.56      0.46      0.50     10000\n",
      "          2       0.62      0.46      0.53     10000\n",
      "          3       0.58      0.44      0.50     10000\n",
      "          4       0.65      0.83      0.73     10000\n",
      "\n",
      "avg / total       0.61      0.62      0.60     50000\n",
      "\n",
      "accuracy: 0.61594\n",
      "epoch 5: train_loss = 0.876830, dev_loss = 1.822095, dev_f1 = 0.6159\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_5.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-29 19:55:44.368039: step 33000/455000 (epoch 6/70), loss = 0.871825 (0.313 sec/batch), lr: 0.010000\n",
      "2019-09-29 20:03:13.923021: step 34000/455000 (epoch 6/70), loss = 0.765140 (0.408 sec/batch), lr: 0.010000\n",
      "2019-09-29 20:10:44.805068: step 35000/455000 (epoch 6/70), loss = 0.947133 (0.363 sec/batch), lr: 0.010000\n",
      "2019-09-29 20:18:13.732050: step 36000/455000 (epoch 6/70), loss = 0.853529 (0.445 sec/batch), lr: 0.010000\n",
      "2019-09-29 20:25:41.432422: step 37000/455000 (epoch 6/70), loss = 0.858789 (0.305 sec/batch), lr: 0.010000\n",
      "2019-09-29 20:33:06.342978: step 38000/455000 (epoch 6/70), loss = 0.790247 (0.554 sec/batch), lr: 0.010000\n",
      "2019-09-29 20:40:31.740658: step 39000/455000 (epoch 6/70), loss = 0.881664 (0.321 sec/batch), lr: 0.010000\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.65      0.89      0.75     10000\n",
      "          1       0.58      0.46      0.51     10000\n",
      "          2       0.63      0.48      0.55     10000\n",
      "          3       0.59      0.44      0.50     10000\n",
      "          4       0.64      0.84      0.73     10000\n",
      "\n",
      "avg / total       0.62      0.62      0.61     50000\n",
      "\n",
      "accuracy: 0.62218\n",
      "epoch 6: train_loss = 0.863180, dev_loss = 1.781219, dev_f1 = 0.6222\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_6.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-29 20:49:13.441785: step 40000/455000 (epoch 7/70), loss = 0.841330 (0.442 sec/batch), lr: 0.010000\n",
      "2019-09-29 20:56:35.965485: step 41000/455000 (epoch 7/70), loss = 0.861388 (0.471 sec/batch), lr: 0.010000\n",
      "2019-09-29 21:03:58.476965: step 42000/455000 (epoch 7/70), loss = 0.813823 (0.307 sec/batch), lr: 0.010000\n",
      "2019-09-29 21:11:16.417651: step 43000/455000 (epoch 7/70), loss = 0.768996 (0.559 sec/batch), lr: 0.010000\n",
      "2019-09-29 21:18:40.096381: step 44000/455000 (epoch 7/70), loss = 0.892917 (0.318 sec/batch), lr: 0.010000\n",
      "2019-09-29 21:26:05.194006: step 45000/455000 (epoch 7/70), loss = 0.727283 (0.436 sec/batch), lr: 0.010000\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.88      0.76     10000\n",
      "          1       0.57      0.50      0.54     10000\n",
      "          2       0.64      0.47      0.54     10000\n",
      "          3       0.58      0.47      0.52     10000\n",
      "          4       0.65      0.83      0.73     10000\n",
      "\n",
      "avg / total       0.62      0.63      0.62     50000\n",
      "\n",
      "accuracy: 0.62954\n",
      "epoch 7: train_loss = 0.852601, dev_loss = 1.734515, dev_f1 = 0.6295\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_7.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-29 21:34:49.202696: step 46000/455000 (epoch 8/70), loss = 0.840665 (0.304 sec/batch), lr: 0.010000\n",
      "2019-09-29 21:42:10.184263: step 47000/455000 (epoch 8/70), loss = 0.778115 (0.401 sec/batch), lr: 0.010000\n",
      "2019-09-29 21:49:32.681152: step 48000/455000 (epoch 8/70), loss = 0.895114 (0.353 sec/batch), lr: 0.010000\n",
      "2019-09-29 21:56:53.623054: step 49000/455000 (epoch 8/70), loss = 0.812640 (0.435 sec/batch), lr: 0.010000\n",
      "2019-09-29 22:04:13.695481: step 50000/455000 (epoch 8/70), loss = 0.920417 (0.299 sec/batch), lr: 0.010000\n",
      "2019-09-29 22:11:37.301566: step 51000/455000 (epoch 8/70), loss = 0.818717 (0.549 sec/batch), lr: 0.010000\n",
      "2019-09-29 22:19:02.422338: step 52000/455000 (epoch 8/70), loss = 0.846397 (0.323 sec/batch), lr: 0.010000\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.87      0.76     10000\n",
      "          1       0.59      0.52      0.55     10000\n",
      "          2       0.63      0.51      0.56     10000\n",
      "          3       0.59      0.42      0.49     10000\n",
      "          4       0.64      0.85      0.73     10000\n",
      "\n",
      "avg / total       0.63      0.63      0.62     50000\n",
      "\n",
      "accuracy: 0.63412\n",
      "epoch 8: train_loss = 0.843211, dev_loss = 1.709976, dev_f1 = 0.6341\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_8.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-29 22:27:43.766575: step 53000/455000 (epoch 9/70), loss = 0.806217 (0.442 sec/batch), lr: 0.010000\n",
      "2019-09-29 22:35:06.004781: step 54000/455000 (epoch 9/70), loss = 0.766803 (0.469 sec/batch), lr: 0.010000\n",
      "2019-09-29 22:42:28.186698: step 55000/455000 (epoch 9/70), loss = 0.804010 (0.307 sec/batch), lr: 0.010000\n",
      "2019-09-29 22:49:46.186510: step 56000/455000 (epoch 9/70), loss = 0.753714 (0.556 sec/batch), lr: 0.010000\n",
      "2019-09-29 22:57:09.803539: step 57000/455000 (epoch 9/70), loss = 0.903124 (0.317 sec/batch), lr: 0.010000\n",
      "2019-09-29 23:04:34.675686: step 58000/455000 (epoch 9/70), loss = 0.703658 (0.435 sec/batch), lr: 0.010000\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.88      0.76     10000\n",
      "          1       0.59      0.51      0.55     10000\n",
      "          2       0.64      0.49      0.56     10000\n",
      "          3       0.58      0.50      0.54     10000\n",
      "          4       0.67      0.82      0.74     10000\n",
      "\n",
      "avg / total       0.63      0.64      0.63     50000\n",
      "\n",
      "accuracy: 0.63878\n",
      "epoch 9: train_loss = 0.836267, dev_loss = 1.705590, dev_f1 = 0.6388\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_9.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-29 23:13:18.970566: step 59000/455000 (epoch 10/70), loss = 0.829081 (0.304 sec/batch), lr: 0.010000\n",
      "2019-09-29 23:20:40.429794: step 60000/455000 (epoch 10/70), loss = 0.745136 (0.404 sec/batch), lr: 0.010000\n",
      "2019-09-29 23:28:03.965723: step 61000/455000 (epoch 10/70), loss = 0.915201 (0.354 sec/batch), lr: 0.010000\n",
      "2019-09-29 23:35:24.606933: step 62000/455000 (epoch 10/70), loss = 0.813150 (0.438 sec/batch), lr: 0.010000\n",
      "2019-09-29 23:42:44.271396: step 63000/455000 (epoch 10/70), loss = 0.857868 (0.297 sec/batch), lr: 0.010000\n",
      "2019-09-29 23:50:08.684112: step 64000/455000 (epoch 10/70), loss = 0.775830 (0.552 sec/batch), lr: 0.010000\n",
      "2019-09-29 23:57:33.701738: step 65000/455000 (epoch 10/70), loss = 0.886065 (0.321 sec/batch), lr: 0.010000\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.87      0.77     10000\n",
      "          1       0.60      0.51      0.55     10000\n",
      "          2       0.64      0.50      0.56     10000\n",
      "          3       0.59      0.47      0.52     10000\n",
      "          4       0.66      0.83      0.73     10000\n",
      "\n",
      "avg / total       0.63      0.64      0.63     50000\n",
      "\n",
      "accuracy: 0.63834\n",
      "epoch 10: train_loss = 0.829046, dev_loss = 1.692903, dev_f1 = 0.6383\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_10.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 00:06:13.075988: step 66000/455000 (epoch 11/70), loss = 0.808925 (0.440 sec/batch), lr: 0.010000\n",
      "2019-09-30 00:13:35.276556: step 67000/455000 (epoch 11/70), loss = 0.868669 (0.471 sec/batch), lr: 0.010000\n",
      "2019-09-30 00:20:57.326499: step 68000/455000 (epoch 11/70), loss = 0.804750 (0.308 sec/batch), lr: 0.010000\n",
      "2019-09-30 00:28:15.332125: step 69000/455000 (epoch 11/70), loss = 0.735056 (0.558 sec/batch), lr: 0.010000\n",
      "2019-09-30 00:35:38.708766: step 70000/455000 (epoch 11/70), loss = 0.915776 (0.319 sec/batch), lr: 0.010000\n",
      "2019-09-30 00:43:03.839160: step 71000/455000 (epoch 11/70), loss = 0.720132 (0.438 sec/batch), lr: 0.010000\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.68      0.87      0.77     10000\n",
      "          1       0.59      0.52      0.55     10000\n",
      "          2       0.64      0.48      0.55     10000\n",
      "          3       0.58      0.49      0.54     10000\n",
      "          4       0.67      0.82      0.74     10000\n",
      "\n",
      "avg / total       0.63      0.64      0.63     50000\n",
      "\n",
      "accuracy: 0.63826\n",
      "epoch 11: train_loss = 0.823667, dev_loss = 1.699632, dev_f1 = 0.6383\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_11.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 00:51:47.344377: step 72000/455000 (epoch 12/70), loss = 0.814988 (0.304 sec/batch), lr: 0.010000\n",
      "2019-09-30 00:59:08.636006: step 73000/455000 (epoch 12/70), loss = 0.820161 (0.399 sec/batch), lr: 0.010000\n",
      "2019-09-30 01:06:31.233156: step 74000/455000 (epoch 12/70), loss = 0.893393 (0.354 sec/batch), lr: 0.010000\n",
      "2019-09-30 01:13:51.996901: step 75000/455000 (epoch 12/70), loss = 0.877701 (0.439 sec/batch), lr: 0.010000\n",
      "2019-09-30 01:21:11.504113: step 76000/455000 (epoch 12/70), loss = 0.871088 (0.301 sec/batch), lr: 0.010000\n",
      "2019-09-30 01:28:36.083864: step 77000/455000 (epoch 12/70), loss = 0.767585 (0.554 sec/batch), lr: 0.010000\n",
      "2019-09-30 01:36:01.775420: step 78000/455000 (epoch 12/70), loss = 0.787313 (0.322 sec/batch), lr: 0.010000\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.86      0.77     10000\n",
      "          1       0.59      0.56      0.58     10000\n",
      "          2       0.65      0.48      0.55     10000\n",
      "          3       0.59      0.47      0.52     10000\n",
      "          4       0.65      0.85      0.74     10000\n",
      "\n",
      "avg / total       0.64      0.64      0.63     50000\n",
      "\n",
      "accuracy: 0.6422\n",
      "epoch 12: train_loss = 0.818201, dev_loss = 1.666967, dev_f1 = 0.6422\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_12.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 01:44:43.376387: step 79000/455000 (epoch 13/70), loss = 0.825486 (0.442 sec/batch), lr: 0.010000\n",
      "2019-09-30 01:52:05.562711: step 80000/455000 (epoch 13/70), loss = 0.851126 (0.470 sec/batch), lr: 0.010000\n",
      "2019-09-30 01:59:27.744551: step 81000/455000 (epoch 13/70), loss = 0.792544 (0.307 sec/batch), lr: 0.010000\n",
      "2019-09-30 02:06:45.678777: step 82000/455000 (epoch 13/70), loss = 0.711747 (0.558 sec/batch), lr: 0.010000\n",
      "2019-09-30 02:14:09.664123: step 83000/455000 (epoch 13/70), loss = 0.840628 (0.316 sec/batch), lr: 0.010000\n",
      "2019-09-30 02:21:35.017815: step 84000/455000 (epoch 13/70), loss = 0.683527 (0.436 sec/batch), lr: 0.010000\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.67      0.88      0.76     10000\n",
      "          1       0.58      0.52      0.55     10000\n",
      "          2       0.64      0.49      0.55     10000\n",
      "          3       0.60      0.49      0.54     10000\n",
      "          4       0.67      0.82      0.74     10000\n",
      "\n",
      "avg / total       0.63      0.64      0.63     50000\n",
      "\n",
      "accuracy: 0.64044\n",
      "epoch 13: train_loss = 0.813545, dev_loss = 1.688872, dev_f1 = 0.6404\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_13.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 02:30:17.845015: step 85000/455000 (epoch 14/70), loss = 0.812461 (0.303 sec/batch), lr: 0.009000\n",
      "2019-09-30 02:37:38.722446: step 86000/455000 (epoch 14/70), loss = 0.716994 (0.403 sec/batch), lr: 0.009000\n",
      "2019-09-30 02:45:01.547493: step 87000/455000 (epoch 14/70), loss = 0.870147 (0.353 sec/batch), lr: 0.009000\n",
      "2019-09-30 02:52:22.272353: step 88000/455000 (epoch 14/70), loss = 0.837128 (0.435 sec/batch), lr: 0.009000\n",
      "2019-09-30 02:59:41.804350: step 89000/455000 (epoch 14/70), loss = 0.892169 (0.297 sec/batch), lr: 0.009000\n",
      "2019-09-30 03:07:05.703618: step 90000/455000 (epoch 14/70), loss = 0.720617 (0.550 sec/batch), lr: 0.009000\n",
      "2019-09-30 03:14:30.649088: step 91000/455000 (epoch 14/70), loss = 0.782412 (0.320 sec/batch), lr: 0.009000\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.86      0.77     10000\n",
      "          1       0.61      0.54      0.57     10000\n",
      "          2       0.64      0.51      0.57     10000\n",
      "          3       0.59      0.49      0.54     10000\n",
      "          4       0.67      0.83      0.74     10000\n",
      "\n",
      "avg / total       0.64      0.65      0.64     50000\n",
      "\n",
      "accuracy: 0.64792\n",
      "epoch 14: train_loss = 0.807150, dev_loss = 1.660495, dev_f1 = 0.6479\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_14.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 03:23:12.104721: step 92000/455000 (epoch 15/70), loss = 0.878055 (0.440 sec/batch), lr: 0.009000\n",
      "2019-09-30 03:30:33.847526: step 93000/455000 (epoch 15/70), loss = 0.761947 (0.467 sec/batch), lr: 0.009000\n",
      "2019-09-30 03:37:55.491037: step 94000/455000 (epoch 15/70), loss = 0.805186 (0.308 sec/batch), lr: 0.009000\n",
      "2019-09-30 03:45:13.091732: step 95000/455000 (epoch 15/70), loss = 0.596215 (0.556 sec/batch), lr: 0.009000\n",
      "2019-09-30 03:52:36.542364: step 96000/455000 (epoch 15/70), loss = 0.809912 (0.316 sec/batch), lr: 0.009000\n",
      "2019-09-30 04:00:01.128660: step 97000/455000 (epoch 15/70), loss = 0.672911 (0.433 sec/batch), lr: 0.009000\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.87      0.77     10000\n",
      "          1       0.59      0.55      0.57     10000\n",
      "          2       0.65      0.49      0.56     10000\n",
      "          3       0.60      0.50      0.55     10000\n",
      "          4       0.68      0.82      0.74     10000\n",
      "\n",
      "avg / total       0.64      0.65      0.64     50000\n",
      "\n",
      "accuracy: 0.6457\n",
      "epoch 15: train_loss = 0.802849, dev_loss = 1.653697, dev_f1 = 0.6457\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_15.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 04:08:43.721275: step 98000/455000 (epoch 16/70), loss = 0.780004 (0.305 sec/batch), lr: 0.008100\n",
      "2019-09-30 04:16:04.974692: step 99000/455000 (epoch 16/70), loss = 0.691286 (0.400 sec/batch), lr: 0.008100\n",
      "2019-09-30 04:23:27.883948: step 100000/455000 (epoch 16/70), loss = 0.859912 (0.353 sec/batch), lr: 0.008100\n",
      "2019-09-30 04:30:48.413279: step 101000/455000 (epoch 16/70), loss = 0.897057 (0.436 sec/batch), lr: 0.008100\n",
      "2019-09-30 04:38:07.651890: step 102000/455000 (epoch 16/70), loss = 0.836982 (0.297 sec/batch), lr: 0.008100\n",
      "2019-09-30 04:45:31.219759: step 103000/455000 (epoch 16/70), loss = 0.708444 (0.549 sec/batch), lr: 0.008100\n",
      "2019-09-30 04:52:56.078125: step 104000/455000 (epoch 16/70), loss = 0.827822 (0.322 sec/batch), lr: 0.008100\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.86      0.77     10000\n",
      "          1       0.60      0.55      0.57     10000\n",
      "          2       0.65      0.51      0.57     10000\n",
      "          3       0.59      0.51      0.55     10000\n",
      "          4       0.67      0.82      0.74     10000\n",
      "\n",
      "avg / total       0.64      0.65      0.64     50000\n",
      "\n",
      "accuracy: 0.64996\n",
      "epoch 16: train_loss = 0.797470, dev_loss = 1.641514, dev_f1 = 0.6500\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_16.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 05:01:38.781855: step 105000/455000 (epoch 17/70), loss = 0.826081 (0.440 sec/batch), lr: 0.008100\n",
      "2019-09-30 05:09:01.141752: step 106000/455000 (epoch 17/70), loss = 0.783659 (0.469 sec/batch), lr: 0.008100\n",
      "2019-09-30 05:16:23.201430: step 107000/455000 (epoch 17/70), loss = 0.796884 (0.308 sec/batch), lr: 0.008100\n",
      "2019-09-30 05:23:41.126816: step 108000/455000 (epoch 17/70), loss = 0.677987 (0.556 sec/batch), lr: 0.008100\n",
      "2019-09-30 05:31:04.424208: step 109000/455000 (epoch 17/70), loss = 0.768890 (0.319 sec/batch), lr: 0.008100\n",
      "2019-09-30 05:38:29.174659: step 110000/455000 (epoch 17/70), loss = 0.686326 (0.434 sec/batch), lr: 0.008100\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.69      0.87      0.77     10000\n",
      "          1       0.60      0.54      0.57     10000\n",
      "          2       0.65      0.50      0.56     10000\n",
      "          3       0.60      0.52      0.55     10000\n",
      "          4       0.68      0.82      0.74     10000\n",
      "\n",
      "avg / total       0.64      0.65      0.64     50000\n",
      "\n",
      "accuracy: 0.64882\n",
      "epoch 17: train_loss = 0.794332, dev_loss = 1.627150, dev_f1 = 0.6488\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_17.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 05:47:11.342718: step 111000/455000 (epoch 18/70), loss = 0.809354 (0.303 sec/batch), lr: 0.007290\n",
      "2019-09-30 05:54:31.901406: step 112000/455000 (epoch 18/70), loss = 0.712534 (0.400 sec/batch), lr: 0.007290\n",
      "2019-09-30 06:01:54.049335: step 113000/455000 (epoch 18/70), loss = 0.874043 (0.351 sec/batch), lr: 0.007290\n",
      "2019-09-30 06:09:14.815726: step 114000/455000 (epoch 18/70), loss = 0.810355 (0.437 sec/batch), lr: 0.007290\n",
      "2019-09-30 06:16:34.295354: step 115000/455000 (epoch 18/70), loss = 0.890786 (0.298 sec/batch), lr: 0.007290\n",
      "2019-09-30 06:23:57.694093: step 116000/455000 (epoch 18/70), loss = 0.743515 (0.553 sec/batch), lr: 0.007290\n",
      "2019-09-30 06:31:22.081054: step 117000/455000 (epoch 18/70), loss = 0.812375 (0.322 sec/batch), lr: 0.007290\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.86      0.78     10000\n",
      "          1       0.60      0.56      0.58     10000\n",
      "          2       0.65      0.50      0.57     10000\n",
      "          3       0.60      0.51      0.55     10000\n",
      "          4       0.68      0.82      0.74     10000\n",
      "\n",
      "avg / total       0.65      0.65      0.64     50000\n",
      "\n",
      "accuracy: 0.6519\n",
      "epoch 18: train_loss = 0.790356, dev_loss = 1.635716, dev_f1 = 0.6519\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_18.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 06:40:03.349142: step 118000/455000 (epoch 19/70), loss = 0.799368 (0.440 sec/batch), lr: 0.007290\n",
      "2019-09-30 06:47:25.257184: step 119000/455000 (epoch 19/70), loss = 0.750575 (0.471 sec/batch), lr: 0.007290\n",
      "2019-09-30 06:54:47.512335: step 120000/455000 (epoch 19/70), loss = 0.790348 (0.308 sec/batch), lr: 0.007290\n",
      "2019-09-30 07:02:04.785795: step 121000/455000 (epoch 19/70), loss = 0.682582 (0.558 sec/batch), lr: 0.007290\n",
      "2019-09-30 07:09:27.718232: step 122000/455000 (epoch 19/70), loss = 0.816055 (0.317 sec/batch), lr: 0.007290\n",
      "2019-09-30 07:16:52.252070: step 123000/455000 (epoch 19/70), loss = 0.614456 (0.436 sec/batch), lr: 0.007290\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.70      0.86      0.77     10000\n",
      "          1       0.60      0.56      0.58     10000\n",
      "          2       0.65      0.50      0.57     10000\n",
      "          3       0.60      0.50      0.54     10000\n",
      "          4       0.67      0.83      0.74     10000\n",
      "\n",
      "avg / total       0.65      0.65      0.64     50000\n",
      "\n",
      "accuracy: 0.65096\n",
      "epoch 19: train_loss = 0.786336, dev_loss = 1.625412, dev_f1 = 0.6510\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_19.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 07:25:33.925699: step 124000/455000 (epoch 20/70), loss = 0.847414 (0.304 sec/batch), lr: 0.006561\n",
      "2019-09-30 07:32:54.373854: step 125000/455000 (epoch 20/70), loss = 0.636517 (0.403 sec/batch), lr: 0.006561\n",
      "2019-09-30 07:40:16.318114: step 126000/455000 (epoch 20/70), loss = 0.875986 (0.352 sec/batch), lr: 0.006561\n",
      "2019-09-30 07:47:36.572257: step 127000/455000 (epoch 20/70), loss = 0.806088 (0.435 sec/batch), lr: 0.006561\n",
      "2019-09-30 07:54:56.000155: step 128000/455000 (epoch 20/70), loss = 0.838909 (0.297 sec/batch), lr: 0.006561\n",
      "2019-09-30 08:02:19.475309: step 129000/455000 (epoch 20/70), loss = 0.683312 (0.553 sec/batch), lr: 0.006561\n",
      "2019-09-30 08:09:43.693758: step 130000/455000 (epoch 20/70), loss = 0.812898 (0.319 sec/batch), lr: 0.006561\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.86      0.78     10000\n",
      "          1       0.61      0.56      0.58     10000\n",
      "          2       0.66      0.49      0.56     10000\n",
      "          3       0.59      0.51      0.54     10000\n",
      "          4       0.67      0.84      0.74     10000\n",
      "\n",
      "avg / total       0.65      0.65      0.64     50000\n",
      "\n",
      "accuracy: 0.65066\n",
      "epoch 20: train_loss = 0.782676, dev_loss = 1.634077, dev_f1 = 0.6507\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_20.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 08:18:22.945154: step 131000/455000 (epoch 21/70), loss = 0.795395 (0.440 sec/batch), lr: 0.005905\n",
      "2019-09-30 08:25:45.083380: step 132000/455000 (epoch 21/70), loss = 0.737882 (0.468 sec/batch), lr: 0.005905\n",
      "2019-09-30 08:33:07.423099: step 133000/455000 (epoch 21/70), loss = 0.715938 (0.307 sec/batch), lr: 0.005905\n",
      "2019-09-30 08:40:24.872002: step 134000/455000 (epoch 21/70), loss = 0.686207 (0.555 sec/batch), lr: 0.005905\n",
      "2019-09-30 08:47:47.869366: step 135000/455000 (epoch 21/70), loss = 0.778533 (0.316 sec/batch), lr: 0.005905\n",
      "2019-09-30 08:55:12.495663: step 136000/455000 (epoch 21/70), loss = 0.585071 (0.436 sec/batch), lr: 0.005905\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.85      0.78     10000\n",
      "          1       0.61      0.59      0.60     10000\n",
      "          2       0.66      0.49      0.56     10000\n",
      "          3       0.59      0.51      0.55     10000\n",
      "          4       0.67      0.83      0.74     10000\n",
      "\n",
      "avg / total       0.65      0.65      0.65     50000\n",
      "\n",
      "accuracy: 0.65426\n",
      "epoch 21: train_loss = 0.779275, dev_loss = 1.614048, dev_f1 = 0.6543\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_21.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 09:03:56.200497: step 137000/455000 (epoch 22/70), loss = 0.775948 (0.303 sec/batch), lr: 0.005905\n",
      "2019-09-30 09:11:17.189194: step 138000/455000 (epoch 22/70), loss = 0.727307 (0.400 sec/batch), lr: 0.005905\n",
      "2019-09-30 09:18:39.570934: step 139000/455000 (epoch 22/70), loss = 0.824441 (0.354 sec/batch), lr: 0.005905\n",
      "2019-09-30 09:25:59.683171: step 140000/455000 (epoch 22/70), loss = 0.743832 (0.437 sec/batch), lr: 0.005905\n",
      "2019-09-30 09:33:18.659619: step 141000/455000 (epoch 22/70), loss = 0.883636 (0.298 sec/batch), lr: 0.005905\n",
      "2019-09-30 09:40:42.735713: step 142000/455000 (epoch 22/70), loss = 0.718848 (0.551 sec/batch), lr: 0.005905\n",
      "2019-09-30 09:48:07.486839: step 143000/455000 (epoch 22/70), loss = 0.786208 (0.320 sec/batch), lr: 0.005905\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.86      0.78     10000\n",
      "          1       0.61      0.56      0.58     10000\n",
      "          2       0.66      0.48      0.56     10000\n",
      "          3       0.58      0.51      0.55     10000\n",
      "          4       0.66      0.84      0.74     10000\n",
      "\n",
      "avg / total       0.65      0.65      0.64     50000\n",
      "\n",
      "accuracy: 0.65054\n",
      "epoch 22: train_loss = 0.777097, dev_loss = 1.634134, dev_f1 = 0.6505\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_22.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 09:56:46.392434: step 144000/455000 (epoch 23/70), loss = 0.715173 (0.440 sec/batch), lr: 0.005314\n",
      "2019-09-30 10:04:08.381288: step 145000/455000 (epoch 23/70), loss = 0.757083 (0.469 sec/batch), lr: 0.005314\n",
      "2019-09-30 10:11:29.910948: step 146000/455000 (epoch 23/70), loss = 0.707757 (0.309 sec/batch), lr: 0.005314\n",
      "2019-09-30 10:18:47.519674: step 147000/455000 (epoch 23/70), loss = 0.700901 (0.557 sec/batch), lr: 0.005314\n",
      "2019-09-30 10:26:10.839192: step 148000/455000 (epoch 23/70), loss = 0.774553 (0.317 sec/batch), lr: 0.005314\n",
      "2019-09-30 10:33:35.617590: step 149000/455000 (epoch 23/70), loss = 0.589420 (0.432 sec/batch), lr: 0.005314\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.86      0.78     10000\n",
      "          1       0.60      0.58      0.59     10000\n",
      "          2       0.66      0.48      0.56     10000\n",
      "          3       0.59      0.53      0.56     10000\n",
      "          4       0.68      0.82      0.75     10000\n",
      "\n",
      "avg / total       0.65      0.65      0.65     50000\n",
      "\n",
      "accuracy: 0.65484\n",
      "epoch 23: train_loss = 0.773262, dev_loss = 1.611341, dev_f1 = 0.6548\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_23.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 10:42:19.635949: step 150000/455000 (epoch 24/70), loss = 0.740499 (0.302 sec/batch), lr: 0.005314\n",
      "2019-09-30 10:49:40.326213: step 151000/455000 (epoch 24/70), loss = 0.693524 (0.401 sec/batch), lr: 0.005314\n",
      "2019-09-30 10:57:02.365655: step 152000/455000 (epoch 24/70), loss = 0.846046 (0.354 sec/batch), lr: 0.005314\n",
      "2019-09-30 11:04:22.553995: step 153000/455000 (epoch 24/70), loss = 0.710224 (0.434 sec/batch), lr: 0.005314\n",
      "2019-09-30 11:11:41.705785: step 154000/455000 (epoch 24/70), loss = 0.820508 (0.299 sec/batch), lr: 0.005314\n",
      "2019-09-30 11:19:05.410846: step 155000/455000 (epoch 24/70), loss = 0.665427 (0.553 sec/batch), lr: 0.005314\n",
      "2019-09-30 11:26:30.596347: step 156000/455000 (epoch 24/70), loss = 0.817541 (0.321 sec/batch), lr: 0.005314\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.86      0.78     10000\n",
      "          1       0.60      0.58      0.59     10000\n",
      "          2       0.67      0.46      0.55     10000\n",
      "          3       0.58      0.53      0.56     10000\n",
      "          4       0.67      0.83      0.74     10000\n",
      "\n",
      "avg / total       0.65      0.65      0.64     50000\n",
      "\n",
      "accuracy: 0.65238\n",
      "epoch 24: train_loss = 0.771453, dev_loss = 1.630957, dev_f1 = 0.6524\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_24.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 11:35:11.268191: step 157000/455000 (epoch 25/70), loss = 0.824613 (0.440 sec/batch), lr: 0.004783\n",
      "2019-09-30 11:42:33.619201: step 158000/455000 (epoch 25/70), loss = 0.702634 (0.468 sec/batch), lr: 0.004783\n",
      "2019-09-30 11:49:56.115033: step 159000/455000 (epoch 25/70), loss = 0.733333 (0.306 sec/batch), lr: 0.004783\n",
      "2019-09-30 11:57:14.308429: step 160000/455000 (epoch 25/70), loss = 0.637532 (0.557 sec/batch), lr: 0.004783\n",
      "2019-09-30 12:04:37.942111: step 161000/455000 (epoch 25/70), loss = 0.771680 (0.316 sec/batch), lr: 0.004783\n",
      "2019-09-30 12:12:03.121756: step 162000/455000 (epoch 25/70), loss = 0.599235 (0.435 sec/batch), lr: 0.004783\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.85      0.78     10000\n",
      "          1       0.61      0.58      0.59     10000\n",
      "          2       0.66      0.49      0.56     10000\n",
      "          3       0.59      0.52      0.55     10000\n",
      "          4       0.67      0.83      0.74     10000\n",
      "\n",
      "avg / total       0.65      0.65      0.65     50000\n",
      "\n",
      "accuracy: 0.65468\n",
      "epoch 25: train_loss = 0.767799, dev_loss = 1.594800, dev_f1 = 0.6547\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_25.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 12:20:46.561231: step 163000/455000 (epoch 26/70), loss = 0.747596 (0.303 sec/batch), lr: 0.004783\n",
      "2019-09-30 12:28:07.904914: step 164000/455000 (epoch 26/70), loss = 0.668006 (0.399 sec/batch), lr: 0.004783\n",
      "2019-09-30 12:35:30.886935: step 165000/455000 (epoch 26/70), loss = 0.820675 (0.353 sec/batch), lr: 0.004783\n",
      "2019-09-30 12:42:51.729918: step 166000/455000 (epoch 26/70), loss = 0.748952 (0.438 sec/batch), lr: 0.004783\n",
      "2019-09-30 12:50:11.524696: step 167000/455000 (epoch 26/70), loss = 0.827880 (0.297 sec/batch), lr: 0.004783\n",
      "2019-09-30 12:57:35.945270: step 168000/455000 (epoch 26/70), loss = 0.730240 (0.552 sec/batch), lr: 0.004783\n",
      "2019-09-30 13:05:01.806795: step 169000/455000 (epoch 26/70), loss = 0.808873 (0.322 sec/batch), lr: 0.004783\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.86      0.78     10000\n",
      "          1       0.60      0.58      0.59     10000\n",
      "          2       0.66      0.49      0.56     10000\n",
      "          3       0.59      0.53      0.56     10000\n",
      "          4       0.68      0.82      0.75     10000\n",
      "\n",
      "avg / total       0.65      0.65      0.65     50000\n",
      "\n",
      "accuracy: 0.65468\n",
      "epoch 26: train_loss = 0.766498, dev_loss = 1.600651, dev_f1 = 0.6547\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_26.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 13:13:41.775836: step 170000/455000 (epoch 27/70), loss = 0.789120 (0.440 sec/batch), lr: 0.004305\n",
      "2019-09-30 13:21:04.090860: step 171000/455000 (epoch 27/70), loss = 0.776294 (0.468 sec/batch), lr: 0.004305\n",
      "2019-09-30 13:28:26.513369: step 172000/455000 (epoch 27/70), loss = 0.730234 (0.306 sec/batch), lr: 0.004305\n",
      "2019-09-30 13:35:45.096852: step 173000/455000 (epoch 27/70), loss = 0.623542 (0.558 sec/batch), lr: 0.004305\n",
      "2019-09-30 13:43:08.989503: step 174000/455000 (epoch 27/70), loss = 0.780501 (0.318 sec/batch), lr: 0.004305\n",
      "2019-09-30 13:50:34.127260: step 175000/455000 (epoch 27/70), loss = 0.614928 (0.437 sec/batch), lr: 0.004305\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.86      0.78     10000\n",
      "          1       0.60      0.59      0.60     10000\n",
      "          2       0.67      0.47      0.56     10000\n",
      "          3       0.59      0.53      0.56     10000\n",
      "          4       0.68      0.83      0.75     10000\n",
      "\n",
      "avg / total       0.65      0.66      0.65     50000\n",
      "\n",
      "accuracy: 0.6557\n",
      "epoch 27: train_loss = 0.763578, dev_loss = 1.631533, dev_f1 = 0.6557\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_27.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 13:59:18.962660: step 176000/455000 (epoch 28/70), loss = 0.729203 (0.303 sec/batch), lr: 0.004305\n",
      "2019-09-30 14:06:40.336670: step 177000/455000 (epoch 28/70), loss = 0.681789 (0.401 sec/batch), lr: 0.004305\n",
      "2019-09-30 14:14:02.897870: step 178000/455000 (epoch 28/70), loss = 0.832777 (0.354 sec/batch), lr: 0.004305\n",
      "2019-09-30 14:21:24.308298: step 179000/455000 (epoch 28/70), loss = 0.760385 (0.437 sec/batch), lr: 0.004305\n",
      "2019-09-30 14:28:44.310839: step 180000/455000 (epoch 28/70), loss = 0.868333 (0.299 sec/batch), lr: 0.004305\n",
      "2019-09-30 14:36:08.674061: step 181000/455000 (epoch 28/70), loss = 0.719339 (0.554 sec/batch), lr: 0.004305\n",
      "2019-09-30 14:43:34.063613: step 182000/455000 (epoch 28/70), loss = 0.762843 (0.321 sec/batch), lr: 0.004305\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.85      0.78     10000\n",
      "          1       0.61      0.59      0.60     10000\n",
      "          2       0.66      0.50      0.57     10000\n",
      "          3       0.60      0.52      0.56     10000\n",
      "          4       0.68      0.83      0.75     10000\n",
      "\n",
      "avg / total       0.65      0.66      0.65     50000\n",
      "\n",
      "accuracy: 0.65754\n",
      "epoch 28: train_loss = 0.761859, dev_loss = 1.608954, dev_f1 = 0.6575\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_28.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 14:52:16.407251: step 183000/455000 (epoch 29/70), loss = 0.838672 (0.439 sec/batch), lr: 0.004305\n",
      "2019-09-30 14:59:39.064986: step 184000/455000 (epoch 29/70), loss = 0.696766 (0.470 sec/batch), lr: 0.004305\n",
      "2019-09-30 15:07:01.684717: step 185000/455000 (epoch 29/70), loss = 0.720555 (0.309 sec/batch), lr: 0.004305\n",
      "2019-09-30 15:14:19.821060: step 186000/455000 (epoch 29/70), loss = 0.696108 (0.555 sec/batch), lr: 0.004305\n",
      "2019-09-30 15:21:43.750108: step 187000/455000 (epoch 29/70), loss = 0.877620 (0.320 sec/batch), lr: 0.004305\n",
      "2019-09-30 15:29:09.270328: step 188000/455000 (epoch 29/70), loss = 0.667934 (0.434 sec/batch), lr: 0.004305\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.71      0.86      0.78     10000\n",
      "          1       0.60      0.58      0.59     10000\n",
      "          2       0.66      0.50      0.57     10000\n",
      "          3       0.60      0.54      0.57     10000\n",
      "          4       0.69      0.81      0.75     10000\n",
      "\n",
      "avg / total       0.65      0.66      0.65     50000\n",
      "\n",
      "accuracy: 0.65854\n",
      "epoch 29: train_loss = 0.760685, dev_loss = 1.599259, dev_f1 = 0.6585\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_29.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 15:37:54.499833: step 189000/455000 (epoch 30/70), loss = 0.758099 (0.305 sec/batch), lr: 0.004305\n",
      "2019-09-30 15:45:16.359549: step 190000/455000 (epoch 30/70), loss = 0.685580 (0.401 sec/batch), lr: 0.004305\n",
      "2019-09-30 15:52:39.481346: step 191000/455000 (epoch 30/70), loss = 0.792464 (0.354 sec/batch), lr: 0.004305\n",
      "2019-09-30 16:00:00.693736: step 192000/455000 (epoch 30/70), loss = 0.757324 (0.437 sec/batch), lr: 0.004305\n",
      "2019-09-30 16:07:20.906411: step 193000/455000 (epoch 30/70), loss = 0.889243 (0.296 sec/batch), lr: 0.004305\n",
      "2019-09-30 16:14:44.870963: step 194000/455000 (epoch 30/70), loss = 0.682342 (0.553 sec/batch), lr: 0.004305\n",
      "2019-09-30 16:22:09.261979: step 195000/455000 (epoch 30/70), loss = 0.815672 (0.321 sec/batch), lr: 0.004305\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.85      0.78     10000\n",
      "          1       0.62      0.58      0.60     10000\n",
      "          2       0.66      0.50      0.57     10000\n",
      "          3       0.59      0.54      0.56     10000\n",
      "          4       0.68      0.83      0.75     10000\n",
      "\n",
      "avg / total       0.65      0.66      0.65     50000\n",
      "\n",
      "accuracy: 0.65844\n",
      "epoch 30: train_loss = 0.758844, dev_loss = 1.609001, dev_f1 = 0.6584\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_30.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 16:30:49.171870: step 196000/455000 (epoch 31/70), loss = 0.800936 (0.440 sec/batch), lr: 0.003874\n",
      "2019-09-30 16:38:11.633795: step 197000/455000 (epoch 31/70), loss = 0.694007 (0.468 sec/batch), lr: 0.003874\n",
      "2019-09-30 16:45:34.205484: step 198000/455000 (epoch 31/70), loss = 0.716282 (0.306 sec/batch), lr: 0.003874\n",
      "2019-09-30 16:52:52.153122: step 199000/455000 (epoch 31/70), loss = 0.595006 (0.555 sec/batch), lr: 0.003874\n",
      "2019-09-30 17:00:15.186747: step 200000/455000 (epoch 31/70), loss = 0.752828 (0.316 sec/batch), lr: 0.003874\n",
      "2019-09-30 17:07:39.546874: step 201000/455000 (epoch 31/70), loss = 0.691072 (0.433 sec/batch), lr: 0.003874\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.85      0.78     10000\n",
      "          1       0.61      0.60      0.60     10000\n",
      "          2       0.67      0.49      0.57     10000\n",
      "          3       0.59      0.54      0.57     10000\n",
      "          4       0.69      0.82      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.66      0.65     50000\n",
      "\n",
      "accuracy: 0.6598\n",
      "epoch 31: train_loss = 0.756684, dev_loss = 1.587774, dev_f1 = 0.6598\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_31.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 17:16:23.871963: step 202000/455000 (epoch 32/70), loss = 0.762740 (0.305 sec/batch), lr: 0.003874\n",
      "2019-09-30 17:23:44.324288: step 203000/455000 (epoch 32/70), loss = 0.695813 (0.400 sec/batch), lr: 0.003874\n",
      "2019-09-30 17:31:06.407292: step 204000/455000 (epoch 32/70), loss = 0.861403 (0.352 sec/batch), lr: 0.003874\n",
      "2019-09-30 17:38:26.338886: step 205000/455000 (epoch 32/70), loss = 0.704299 (0.439 sec/batch), lr: 0.003874\n",
      "2019-09-30 17:45:45.248154: step 206000/455000 (epoch 32/70), loss = 0.889637 (0.298 sec/batch), lr: 0.003874\n",
      "2019-09-30 17:53:08.332223: step 207000/455000 (epoch 32/70), loss = 0.664606 (0.552 sec/batch), lr: 0.003874\n",
      "2019-09-30 18:00:32.510291: step 208000/455000 (epoch 32/70), loss = 0.752113 (0.322 sec/batch), lr: 0.003874\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.84      0.78     10000\n",
      "          1       0.61      0.58      0.60     10000\n",
      "          2       0.66      0.50      0.57     10000\n",
      "          3       0.59      0.54      0.56     10000\n",
      "          4       0.69      0.83      0.75     10000\n",
      "\n",
      "avg / total       0.65      0.66      0.65     50000\n",
      "\n",
      "accuracy: 0.65978\n",
      "epoch 32: train_loss = 0.755251, dev_loss = 1.588873, dev_f1 = 0.6598\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_32.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 18:09:11.618516: step 209000/455000 (epoch 33/70), loss = 0.777434 (0.442 sec/batch), lr: 0.003487\n",
      "2019-09-30 18:16:33.086542: step 210000/455000 (epoch 33/70), loss = 0.716731 (0.469 sec/batch), lr: 0.003487\n",
      "2019-09-30 18:23:54.548461: step 211000/455000 (epoch 33/70), loss = 0.722286 (0.307 sec/batch), lr: 0.003487\n",
      "2019-09-30 18:31:11.646339: step 212000/455000 (epoch 33/70), loss = 0.691283 (0.556 sec/batch), lr: 0.003487\n",
      "2019-09-30 18:38:34.936597: step 213000/455000 (epoch 33/70), loss = 0.778947 (0.317 sec/batch), lr: 0.003487\n",
      "2019-09-30 18:46:00.143958: step 214000/455000 (epoch 33/70), loss = 0.666054 (0.434 sec/batch), lr: 0.003487\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.84      0.78     10000\n",
      "          1       0.61      0.60      0.61     10000\n",
      "          2       0.66      0.50      0.57     10000\n",
      "          3       0.59      0.54      0.56     10000\n",
      "          4       0.68      0.83      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.66      0.65     50000\n",
      "\n",
      "accuracy: 0.66018\n",
      "epoch 33: train_loss = 0.752155, dev_loss = 1.593730, dev_f1 = 0.6602\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_33.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 18:54:44.732593: step 215000/455000 (epoch 34/70), loss = 0.743556 (0.303 sec/batch), lr: 0.003487\n",
      "2019-09-30 19:02:05.629992: step 216000/455000 (epoch 34/70), loss = 0.656319 (0.403 sec/batch), lr: 0.003487\n",
      "2019-09-30 19:09:28.119674: step 217000/455000 (epoch 34/70), loss = 0.879987 (0.352 sec/batch), lr: 0.003487\n",
      "2019-09-30 19:16:48.560884: step 218000/455000 (epoch 34/70), loss = 0.698888 (0.436 sec/batch), lr: 0.003487\n",
      "2019-09-30 19:24:07.652716: step 219000/455000 (epoch 34/70), loss = 0.835899 (0.296 sec/batch), lr: 0.003487\n",
      "2019-09-30 19:31:31.169375: step 220000/455000 (epoch 34/70), loss = 0.679686 (0.549 sec/batch), lr: 0.003487\n",
      "2019-09-30 19:38:55.804224: step 221000/455000 (epoch 34/70), loss = 0.750013 (0.320 sec/batch), lr: 0.003487\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.72      0.85      0.78     10000\n",
      "          1       0.60      0.60      0.60     10000\n",
      "          2       0.66      0.49      0.56     10000\n",
      "          3       0.60      0.53      0.56     10000\n",
      "          4       0.68      0.83      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.66      0.65     50000\n",
      "\n",
      "accuracy: 0.65952\n",
      "epoch 34: train_loss = 0.751713, dev_loss = 1.593857, dev_f1 = 0.6595\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_34.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 19:47:36.264677: step 222000/455000 (epoch 35/70), loss = 0.808817 (0.441 sec/batch), lr: 0.003138\n",
      "2019-09-30 19:54:58.298099: step 223000/455000 (epoch 35/70), loss = 0.695714 (0.470 sec/batch), lr: 0.003138\n",
      "2019-09-30 20:02:20.170229: step 224000/455000 (epoch 35/70), loss = 0.691237 (0.307 sec/batch), lr: 0.003138\n",
      "2019-09-30 20:09:37.858888: step 225000/455000 (epoch 35/70), loss = 0.631692 (0.555 sec/batch), lr: 0.003138\n",
      "2019-09-30 20:17:01.293031: step 226000/455000 (epoch 35/70), loss = 0.812907 (0.317 sec/batch), lr: 0.003138\n",
      "2019-09-30 20:24:26.240890: step 227000/455000 (epoch 35/70), loss = 0.702774 (0.433 sec/batch), lr: 0.003138\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.85      0.78     10000\n",
      "          1       0.60      0.61      0.60     10000\n",
      "          2       0.67      0.49      0.56     10000\n",
      "          3       0.60      0.54      0.57     10000\n",
      "          4       0.69      0.82      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.66      0.65     50000\n",
      "\n",
      "accuracy: 0.66094\n",
      "epoch 35: train_loss = 0.748962, dev_loss = 1.586755, dev_f1 = 0.6609\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_35.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 20:33:10.891227: step 228000/455000 (epoch 36/70), loss = 0.723025 (0.303 sec/batch), lr: 0.003138\n",
      "2019-09-30 20:40:32.125880: step 229000/455000 (epoch 36/70), loss = 0.677965 (0.399 sec/batch), lr: 0.003138\n",
      "2019-09-30 20:47:54.947002: step 230000/455000 (epoch 36/70), loss = 0.802946 (0.355 sec/batch), lr: 0.003138\n",
      "2019-09-30 20:55:16.152662: step 231000/455000 (epoch 36/70), loss = 0.726915 (0.439 sec/batch), lr: 0.003138\n",
      "2019-09-30 21:02:36.090773: step 232000/455000 (epoch 36/70), loss = 0.850571 (0.297 sec/batch), lr: 0.003138\n",
      "2019-09-30 21:10:00.421179: step 233000/455000 (epoch 36/70), loss = 0.689174 (0.551 sec/batch), lr: 0.003138\n",
      "2019-09-30 21:17:25.705868: step 234000/455000 (epoch 36/70), loss = 0.747990 (0.320 sec/batch), lr: 0.003138\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.84      0.78     10000\n",
      "          1       0.61      0.60      0.61     10000\n",
      "          2       0.66      0.51      0.58     10000\n",
      "          3       0.60      0.54      0.57     10000\n",
      "          4       0.69      0.82      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.66      0.66     50000\n",
      "\n",
      "accuracy: 0.66292\n",
      "epoch 36: train_loss = 0.748512, dev_loss = 1.567042, dev_f1 = 0.6629\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_36.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 21:26:08.095078: step 235000/455000 (epoch 37/70), loss = 0.774964 (0.441 sec/batch), lr: 0.003138\n",
      "2019-09-30 21:33:30.395167: step 236000/455000 (epoch 37/70), loss = 0.615964 (0.472 sec/batch), lr: 0.003138\n",
      "2019-09-30 21:40:52.562761: step 237000/455000 (epoch 37/70), loss = 0.757682 (0.308 sec/batch), lr: 0.003138\n",
      "2019-09-30 21:48:10.555567: step 238000/455000 (epoch 37/70), loss = 0.622719 (0.554 sec/batch), lr: 0.003138\n",
      "2019-09-30 21:55:33.951416: step 239000/455000 (epoch 37/70), loss = 0.777847 (0.318 sec/batch), lr: 0.003138\n",
      "2019-09-30 22:02:58.977059: step 240000/455000 (epoch 37/70), loss = 0.624764 (0.434 sec/batch), lr: 0.003138\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.84      0.78     10000\n",
      "          1       0.61      0.60      0.61     10000\n",
      "          2       0.66      0.51      0.57     10000\n",
      "          3       0.59      0.55      0.57     10000\n",
      "          4       0.69      0.82      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.66      0.66     50000\n",
      "\n",
      "accuracy: 0.66358\n",
      "epoch 37: train_loss = 0.747147, dev_loss = 1.578602, dev_f1 = 0.6636\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_37.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 22:11:43.775391: step 241000/455000 (epoch 38/70), loss = 0.748674 (0.305 sec/batch), lr: 0.003138\n",
      "2019-09-30 22:19:04.939046: step 242000/455000 (epoch 38/70), loss = 0.627858 (0.401 sec/batch), lr: 0.003138\n",
      "2019-09-30 22:26:27.650701: step 243000/455000 (epoch 38/70), loss = 0.839045 (0.353 sec/batch), lr: 0.003138\n",
      "2019-09-30 22:33:48.343044: step 244000/455000 (epoch 38/70), loss = 0.714888 (0.435 sec/batch), lr: 0.003138\n",
      "2019-09-30 22:41:07.996520: step 245000/455000 (epoch 38/70), loss = 0.912226 (0.299 sec/batch), lr: 0.003138\n",
      "2019-09-30 22:48:31.874740: step 246000/455000 (epoch 38/70), loss = 0.695265 (0.550 sec/batch), lr: 0.003138\n",
      "2019-09-30 22:55:56.703352: step 247000/455000 (epoch 38/70), loss = 0.752146 (0.321 sec/batch), lr: 0.003138\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.84      0.79     10000\n",
      "          1       0.61      0.61      0.61     10000\n",
      "          2       0.66      0.52      0.58     10000\n",
      "          3       0.60      0.55      0.57     10000\n",
      "          4       0.70      0.81      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.6655\n",
      "epoch 38: train_loss = 0.746095, dev_loss = 1.573756, dev_f1 = 0.6655\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_38.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 23:04:38.781274: step 248000/455000 (epoch 39/70), loss = 0.773066 (0.440 sec/batch), lr: 0.003138\n",
      "2019-09-30 23:12:00.874265: step 249000/455000 (epoch 39/70), loss = 0.673805 (0.470 sec/batch), lr: 0.003138\n",
      "2019-09-30 23:19:23.045753: step 250000/455000 (epoch 39/70), loss = 0.732252 (0.308 sec/batch), lr: 0.003138\n",
      "2019-09-30 23:26:40.780357: step 251000/455000 (epoch 39/70), loss = 0.646939 (0.556 sec/batch), lr: 0.003138\n",
      "2019-09-30 23:34:03.902228: step 252000/455000 (epoch 39/70), loss = 0.794523 (0.317 sec/batch), lr: 0.003138\n",
      "2019-09-30 23:41:28.789856: step 253000/455000 (epoch 39/70), loss = 0.636132 (0.436 sec/batch), lr: 0.003138\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.85      0.78     10000\n",
      "          1       0.61      0.60      0.60     10000\n",
      "          2       0.67      0.49      0.57     10000\n",
      "          3       0.60      0.53      0.56     10000\n",
      "          4       0.68      0.83      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.66      0.65     50000\n",
      "\n",
      "accuracy: 0.6607\n",
      "epoch 39: train_loss = 0.744667, dev_loss = 1.601420, dev_f1 = 0.6607\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_39.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-09-30 23:50:11.048694: step 254000/455000 (epoch 40/70), loss = 0.781809 (0.304 sec/batch), lr: 0.002824\n",
      "2019-09-30 23:57:32.166059: step 255000/455000 (epoch 40/70), loss = 0.664581 (0.400 sec/batch), lr: 0.002824\n",
      "2019-10-01 00:04:54.832583: step 256000/455000 (epoch 40/70), loss = 0.868776 (0.354 sec/batch), lr: 0.002824\n",
      "2019-10-01 00:12:15.674483: step 257000/455000 (epoch 40/70), loss = 0.702293 (0.434 sec/batch), lr: 0.002824\n",
      "2019-10-01 00:19:34.673086: step 258000/455000 (epoch 40/70), loss = 0.807076 (0.297 sec/batch), lr: 0.002824\n",
      "2019-10-01 00:26:58.101847: step 259000/455000 (epoch 40/70), loss = 0.689523 (0.551 sec/batch), lr: 0.002824\n",
      "2019-10-01 00:34:22.549500: step 260000/455000 (epoch 40/70), loss = 0.758817 (0.319 sec/batch), lr: 0.002824\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.85      0.78     10000\n",
      "          1       0.61      0.61      0.61     10000\n",
      "          2       0.67      0.50      0.57     10000\n",
      "          3       0.60      0.53      0.56     10000\n",
      "          4       0.68      0.83      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.66      0.65     50000\n",
      "\n",
      "accuracy: 0.66222\n",
      "epoch 40: train_loss = 0.743336, dev_loss = 1.584069, dev_f1 = 0.6622\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_40.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 00:43:02.474706: step 261000/455000 (epoch 41/70), loss = 0.817160 (0.439 sec/batch), lr: 0.002824\n",
      "2019-10-01 00:50:24.476463: step 262000/455000 (epoch 41/70), loss = 0.667423 (0.471 sec/batch), lr: 0.002824\n",
      "2019-10-01 00:57:46.321600: step 263000/455000 (epoch 41/70), loss = 0.691841 (0.306 sec/batch), lr: 0.002824\n",
      "2019-10-01 01:05:03.754792: step 264000/455000 (epoch 41/70), loss = 0.655846 (0.559 sec/batch), lr: 0.002824\n",
      "2019-10-01 01:12:26.839094: step 265000/455000 (epoch 41/70), loss = 0.727358 (0.317 sec/batch), lr: 0.002824\n",
      "2019-10-01 01:19:51.312545: step 266000/455000 (epoch 41/70), loss = 0.681879 (0.430 sec/batch), lr: 0.002824\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.84      0.79     10000\n",
      "          1       0.61      0.62      0.61     10000\n",
      "          2       0.67      0.51      0.58     10000\n",
      "          3       0.61      0.54      0.57     10000\n",
      "          4       0.69      0.83      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.66666\n",
      "epoch 41: train_loss = 0.742246, dev_loss = 1.566213, dev_f1 = 0.6667\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_41.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 01:28:35.724321: step 267000/455000 (epoch 42/70), loss = 0.769695 (0.302 sec/batch), lr: 0.002824\n",
      "2019-10-01 01:35:56.534541: step 268000/455000 (epoch 42/70), loss = 0.653057 (0.402 sec/batch), lr: 0.002824\n",
      "2019-10-01 01:43:18.837552: step 269000/455000 (epoch 42/70), loss = 0.807042 (0.354 sec/batch), lr: 0.002824\n",
      "2019-10-01 01:50:39.373454: step 270000/455000 (epoch 42/70), loss = 0.707997 (0.436 sec/batch), lr: 0.002824\n",
      "2019-10-01 01:57:58.806288: step 271000/455000 (epoch 42/70), loss = 0.847387 (0.299 sec/batch), lr: 0.002824\n",
      "2019-10-01 02:05:22.651432: step 272000/455000 (epoch 42/70), loss = 0.634149 (0.549 sec/batch), lr: 0.002824\n",
      "2019-10-01 02:12:47.359031: step 273000/455000 (epoch 42/70), loss = 0.751348 (0.321 sec/batch), lr: 0.002824\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.73      0.85      0.78     10000\n",
      "          1       0.62      0.59      0.60     10000\n",
      "          2       0.67      0.51      0.58     10000\n",
      "          3       0.60      0.55      0.57     10000\n",
      "          4       0.69      0.82      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.66      0.66     50000\n",
      "\n",
      "accuracy: 0.6642\n",
      "epoch 42: train_loss = 0.740702, dev_loss = 1.581016, dev_f1 = 0.6642\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_42.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 02:21:27.166200: step 274000/455000 (epoch 43/70), loss = 0.847154 (0.443 sec/batch), lr: 0.002542\n",
      "2019-10-01 02:28:48.925948: step 275000/455000 (epoch 43/70), loss = 0.672241 (0.471 sec/batch), lr: 0.002542\n",
      "2019-10-01 02:36:10.437073: step 276000/455000 (epoch 43/70), loss = 0.729433 (0.307 sec/batch), lr: 0.002542\n",
      "2019-10-01 02:43:27.576665: step 277000/455000 (epoch 43/70), loss = 0.645804 (0.557 sec/batch), lr: 0.002542\n",
      "2019-10-01 02:50:50.392192: step 278000/455000 (epoch 43/70), loss = 0.704633 (0.316 sec/batch), lr: 0.002542\n",
      "2019-10-01 02:58:14.633857: step 279000/455000 (epoch 43/70), loss = 0.615538 (0.435 sec/batch), lr: 0.002542\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.83      0.78     10000\n",
      "          1       0.60      0.62      0.61     10000\n",
      "          2       0.66      0.52      0.58     10000\n",
      "          3       0.60      0.55      0.58     10000\n",
      "          4       0.70      0.81      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.666\n",
      "epoch 43: train_loss = 0.739838, dev_loss = 1.568621, dev_f1 = 0.6660\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_43.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 03:06:57.027908: step 280000/455000 (epoch 44/70), loss = 0.747038 (0.303 sec/batch), lr: 0.002542\n",
      "2019-10-01 03:14:17.292617: step 281000/455000 (epoch 44/70), loss = 0.640688 (0.401 sec/batch), lr: 0.002542\n",
      "2019-10-01 03:21:39.086816: step 282000/455000 (epoch 44/70), loss = 0.778189 (0.352 sec/batch), lr: 0.002542\n",
      "2019-10-01 03:28:59.176677: step 283000/455000 (epoch 44/70), loss = 0.718688 (0.436 sec/batch), lr: 0.002542\n",
      "2019-10-01 03:36:18.209074: step 284000/455000 (epoch 44/70), loss = 0.826961 (0.299 sec/batch), lr: 0.002542\n",
      "2019-10-01 03:43:41.691698: step 285000/455000 (epoch 44/70), loss = 0.730284 (0.554 sec/batch), lr: 0.002542\n",
      "2019-10-01 03:51:06.042859: step 286000/455000 (epoch 44/70), loss = 0.775787 (0.321 sec/batch), lr: 0.002542\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.84      0.79     10000\n",
      "          1       0.61      0.62      0.61     10000\n",
      "          2       0.66      0.52      0.58     10000\n",
      "          3       0.61      0.55      0.58     10000\n",
      "          4       0.70      0.81      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.6672\n",
      "epoch 44: train_loss = 0.738416, dev_loss = 1.548503, dev_f1 = 0.6672\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_44.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 03:59:47.429409: step 287000/455000 (epoch 45/70), loss = 0.779895 (0.441 sec/batch), lr: 0.002542\n",
      "2019-10-01 04:07:08.863925: step 288000/455000 (epoch 45/70), loss = 0.722578 (0.468 sec/batch), lr: 0.002542\n",
      "2019-10-01 04:14:30.356361: step 289000/455000 (epoch 45/70), loss = 0.703163 (0.308 sec/batch), lr: 0.002542\n",
      "2019-10-01 04:21:47.624881: step 290000/455000 (epoch 45/70), loss = 0.607263 (0.556 sec/batch), lr: 0.002542\n",
      "2019-10-01 04:29:10.285266: step 291000/455000 (epoch 45/70), loss = 0.769912 (0.317 sec/batch), lr: 0.002542\n",
      "2019-10-01 04:36:34.425474: step 292000/455000 (epoch 45/70), loss = 0.644202 (0.436 sec/batch), lr: 0.002542\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.83      0.79     10000\n",
      "          1       0.61      0.62      0.62     10000\n",
      "          2       0.65      0.54      0.59     10000\n",
      "          3       0.60      0.56      0.58     10000\n",
      "          4       0.71      0.80      0.75     10000\n",
      "\n",
      "avg / total       0.67      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.66906\n",
      "epoch 45: train_loss = 0.737686, dev_loss = 1.541380, dev_f1 = 0.6691\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_45.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 04:45:20.211011: step 293000/455000 (epoch 46/70), loss = 0.692613 (0.306 sec/batch), lr: 0.002542\n",
      "2019-10-01 04:52:47.706964: step 294000/455000 (epoch 46/70), loss = 0.677402 (0.405 sec/batch), lr: 0.002542\n",
      "2019-10-01 05:00:17.675537: step 295000/455000 (epoch 46/70), loss = 0.809594 (0.358 sec/batch), lr: 0.002542\n",
      "2019-10-01 05:07:45.556919: step 296000/455000 (epoch 46/70), loss = 0.739324 (0.444 sec/batch), lr: 0.002542\n",
      "2019-10-01 05:15:12.173521: step 297000/455000 (epoch 46/70), loss = 0.780661 (0.305 sec/batch), lr: 0.002542\n",
      "2019-10-01 05:22:43.147287: step 298000/455000 (epoch 46/70), loss = 0.653952 (0.556 sec/batch), lr: 0.002542\n",
      "2019-10-01 05:30:14.912187: step 299000/455000 (epoch 46/70), loss = 0.778192 (0.324 sec/batch), lr: 0.002542\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.84      0.79     10000\n",
      "          1       0.62      0.60      0.61     10000\n",
      "          2       0.67      0.51      0.58     10000\n",
      "          3       0.59      0.55      0.57     10000\n",
      "          4       0.69      0.82      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.66526\n",
      "epoch 46: train_loss = 0.736851, dev_loss = 1.579441, dev_f1 = 0.6653\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_46.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 05:39:03.330310: step 300000/455000 (epoch 47/70), loss = 0.796491 (0.447 sec/batch), lr: 0.002288\n",
      "2019-10-01 05:46:32.263649: step 301000/455000 (epoch 47/70), loss = 0.720373 (0.475 sec/batch), lr: 0.002288\n",
      "2019-10-01 05:54:01.459009: step 302000/455000 (epoch 47/70), loss = 0.739746 (0.314 sec/batch), lr: 0.002288\n",
      "2019-10-01 06:01:25.932154: step 303000/455000 (epoch 47/70), loss = 0.586947 (0.565 sec/batch), lr: 0.002288\n",
      "2019-10-01 06:08:56.360222: step 304000/455000 (epoch 47/70), loss = 0.732680 (0.323 sec/batch), lr: 0.002288\n",
      "2019-10-01 06:16:28.196770: step 305000/455000 (epoch 47/70), loss = 0.580179 (0.440 sec/batch), lr: 0.002288\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.84      0.79     10000\n",
      "          1       0.61      0.61      0.61     10000\n",
      "          2       0.66      0.51      0.58     10000\n",
      "          3       0.60      0.56      0.58     10000\n",
      "          4       0.70      0.81      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.66664\n",
      "epoch 47: train_loss = 0.735405, dev_loss = 1.554797, dev_f1 = 0.6666\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_47.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 06:25:19.537201: step 306000/455000 (epoch 48/70), loss = 0.727218 (0.313 sec/batch), lr: 0.002288\n",
      "2019-10-01 06:32:47.267382: step 307000/455000 (epoch 48/70), loss = 0.670034 (0.406 sec/batch), lr: 0.002288\n",
      "2019-10-01 06:40:16.977014: step 308000/455000 (epoch 48/70), loss = 0.803361 (0.362 sec/batch), lr: 0.002288\n",
      "2019-10-01 06:47:44.587392: step 309000/455000 (epoch 48/70), loss = 0.720538 (0.442 sec/batch), lr: 0.002288\n",
      "2019-10-01 06:55:11.180599: step 310000/455000 (epoch 48/70), loss = 0.797208 (0.304 sec/batch), lr: 0.002288\n",
      "2019-10-01 07:02:42.421387: step 311000/455000 (epoch 48/70), loss = 0.656869 (0.557 sec/batch), lr: 0.002288\n",
      "2019-10-01 07:10:14.564869: step 312000/455000 (epoch 48/70), loss = 0.771337 (0.325 sec/batch), lr: 0.002288\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.84      0.79     10000\n",
      "          1       0.61      0.62      0.62     10000\n",
      "          2       0.66      0.52      0.58     10000\n",
      "          3       0.60      0.56      0.58     10000\n",
      "          4       0.71      0.80      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.66752\n",
      "epoch 48: train_loss = 0.734272, dev_loss = 1.564110, dev_f1 = 0.6675\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_48.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 07:19:03.261759: step 313000/455000 (epoch 49/70), loss = 0.753103 (0.448 sec/batch), lr: 0.002288\n",
      "2019-10-01 07:26:32.202534: step 314000/455000 (epoch 49/70), loss = 0.630520 (0.476 sec/batch), lr: 0.002288\n",
      "2019-10-01 07:34:01.420728: step 315000/455000 (epoch 49/70), loss = 0.761749 (0.313 sec/batch), lr: 0.002288\n",
      "2019-10-01 07:41:26.214360: step 316000/455000 (epoch 49/70), loss = 0.630926 (0.567 sec/batch), lr: 0.002288\n",
      "2019-10-01 07:48:56.695111: step 317000/455000 (epoch 49/70), loss = 0.783906 (0.323 sec/batch), lr: 0.002288\n",
      "2019-10-01 07:56:28.789866: step 318000/455000 (epoch 49/70), loss = 0.630347 (0.440 sec/batch), lr: 0.002288\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.84      0.79     10000\n",
      "          1       0.61      0.62      0.61     10000\n",
      "          2       0.66      0.53      0.58     10000\n",
      "          3       0.61      0.55      0.57     10000\n",
      "          4       0.70      0.81      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.66804\n",
      "epoch 49: train_loss = 0.733257, dev_loss = 1.560306, dev_f1 = 0.6680\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_49.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 08:05:20.324943: step 319000/455000 (epoch 50/70), loss = 0.743717 (0.313 sec/batch), lr: 0.002288\n",
      "2019-10-01 08:12:48.466748: step 320000/455000 (epoch 50/70), loss = 0.655350 (0.405 sec/batch), lr: 0.002288\n",
      "2019-10-01 08:20:18.236425: step 321000/455000 (epoch 50/70), loss = 0.822639 (0.361 sec/batch), lr: 0.002288\n",
      "2019-10-01 08:27:45.893310: step 322000/455000 (epoch 50/70), loss = 0.655962 (0.442 sec/batch), lr: 0.002288\n",
      "2019-10-01 08:35:12.660915: step 323000/455000 (epoch 50/70), loss = 0.865267 (0.304 sec/batch), lr: 0.002288\n",
      "2019-10-01 08:42:44.725958: step 324000/455000 (epoch 50/70), loss = 0.656001 (0.558 sec/batch), lr: 0.002288\n",
      "2019-10-01 08:50:17.924737: step 325000/455000 (epoch 50/70), loss = 0.733635 (0.327 sec/batch), lr: 0.002288\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.83      0.79     10000\n",
      "          1       0.61      0.62      0.61     10000\n",
      "          2       0.66      0.53      0.59     10000\n",
      "          3       0.60      0.55      0.58     10000\n",
      "          4       0.70      0.81      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.66814\n",
      "epoch 50: train_loss = 0.732645, dev_loss = 1.557842, dev_f1 = 0.6681\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_50.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 08:59:06.036709: step 326000/455000 (epoch 51/70), loss = 0.834542 (0.440 sec/batch), lr: 0.002288\n",
      "2019-10-01 09:06:28.167955: step 327000/455000 (epoch 51/70), loss = 0.652863 (0.468 sec/batch), lr: 0.002288\n",
      "2019-10-01 09:13:50.248897: step 328000/455000 (epoch 51/70), loss = 0.723540 (0.307 sec/batch), lr: 0.002288\n",
      "2019-10-01 09:21:07.819317: step 329000/455000 (epoch 51/70), loss = 0.637441 (0.556 sec/batch), lr: 0.002288\n",
      "2019-10-01 09:28:31.044083: step 330000/455000 (epoch 51/70), loss = 0.761412 (0.316 sec/batch), lr: 0.002288\n",
      "2019-10-01 09:35:55.593581: step 331000/455000 (epoch 51/70), loss = 0.594970 (0.432 sec/batch), lr: 0.002288\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.84      0.79     10000\n",
      "          1       0.62      0.60      0.61     10000\n",
      "          2       0.66      0.52      0.58     10000\n",
      "          3       0.60      0.55      0.57     10000\n",
      "          4       0.69      0.82      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.66682\n",
      "epoch 51: train_loss = 0.731989, dev_loss = 1.563678, dev_f1 = 0.6668\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_51.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 09:44:37.993988: step 332000/455000 (epoch 52/70), loss = 0.772137 (0.303 sec/batch), lr: 0.002059\n",
      "2019-10-01 09:51:58.803635: step 333000/455000 (epoch 52/70), loss = 0.592755 (0.400 sec/batch), lr: 0.002059\n",
      "2019-10-01 09:59:21.007921: step 334000/455000 (epoch 52/70), loss = 0.814566 (0.353 sec/batch), lr: 0.002059\n",
      "2019-10-01 10:06:41.564408: step 335000/455000 (epoch 52/70), loss = 0.657609 (0.439 sec/batch), lr: 0.002059\n",
      "2019-10-01 10:14:01.062280: step 336000/455000 (epoch 52/70), loss = 0.804992 (0.298 sec/batch), lr: 0.002059\n",
      "2019-10-01 10:21:25.099535: step 337000/455000 (epoch 52/70), loss = 0.743177 (0.552 sec/batch), lr: 0.002059\n",
      "2019-10-01 10:28:49.933527: step 338000/455000 (epoch 52/70), loss = 0.772574 (0.321 sec/batch), lr: 0.002059\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.83      0.79     10000\n",
      "          1       0.61      0.62      0.62     10000\n",
      "          2       0.66      0.53      0.59     10000\n",
      "          3       0.60      0.57      0.58     10000\n",
      "          4       0.71      0.80      0.75     10000\n",
      "\n",
      "avg / total       0.67      0.67      0.67     50000\n",
      "\n",
      "accuracy: 0.67012\n",
      "epoch 52: train_loss = 0.730614, dev_loss = 1.549545, dev_f1 = 0.6701\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_52.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 10:37:31.661381: step 339000/455000 (epoch 53/70), loss = 0.846898 (0.440 sec/batch), lr: 0.002059\n",
      "2019-10-01 10:44:53.513437: step 340000/455000 (epoch 53/70), loss = 0.682402 (0.469 sec/batch), lr: 0.002059\n",
      "2019-10-01 10:52:15.588215: step 341000/455000 (epoch 53/70), loss = 0.727629 (0.308 sec/batch), lr: 0.002059\n",
      "2019-10-01 10:59:33.280036: step 342000/455000 (epoch 53/70), loss = 0.562270 (0.556 sec/batch), lr: 0.002059\n",
      "2019-10-01 11:06:56.333248: step 343000/455000 (epoch 53/70), loss = 0.778139 (0.317 sec/batch), lr: 0.002059\n",
      "2019-10-01 11:14:20.879065: step 344000/455000 (epoch 53/70), loss = 0.542788 (0.434 sec/batch), lr: 0.002059\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.83      0.79     10000\n",
      "          1       0.62      0.60      0.61     10000\n",
      "          2       0.66      0.53      0.59     10000\n",
      "          3       0.60      0.56      0.58     10000\n",
      "          4       0.70      0.81      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.66782\n",
      "epoch 53: train_loss = 0.730197, dev_loss = 1.559940, dev_f1 = 0.6678\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_53.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 11:23:03.101481: step 345000/455000 (epoch 54/70), loss = 0.714010 (0.305 sec/batch), lr: 0.001853\n",
      "2019-10-01 11:30:23.700066: step 346000/455000 (epoch 54/70), loss = 0.584322 (0.403 sec/batch), lr: 0.001853\n",
      "2019-10-01 11:37:45.995765: step 347000/455000 (epoch 54/70), loss = 0.767946 (0.352 sec/batch), lr: 0.001853\n",
      "2019-10-01 11:45:06.460198: step 348000/455000 (epoch 54/70), loss = 0.680287 (0.440 sec/batch), lr: 0.001853\n",
      "2019-10-01 11:52:26.161461: step 349000/455000 (epoch 54/70), loss = 0.904626 (0.299 sec/batch), lr: 0.001853\n",
      "2019-10-01 11:59:50.846253: step 350000/455000 (epoch 54/70), loss = 0.626652 (0.551 sec/batch), lr: 0.001853\n",
      "2019-10-01 12:07:16.306786: step 351000/455000 (epoch 54/70), loss = 0.701405 (0.321 sec/batch), lr: 0.001853\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.84      0.79     10000\n",
      "          1       0.62      0.60      0.61     10000\n",
      "          2       0.66      0.53      0.59     10000\n",
      "          3       0.61      0.55      0.58     10000\n",
      "          4       0.70      0.81      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.6683\n",
      "epoch 54: train_loss = 0.728572, dev_loss = 1.556085, dev_f1 = 0.6683\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_54.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 12:15:55.909539: step 352000/455000 (epoch 55/70), loss = 0.771373 (0.437 sec/batch), lr: 0.001853\n",
      "2019-10-01 12:23:18.030597: step 353000/455000 (epoch 55/70), loss = 0.704400 (0.468 sec/batch), lr: 0.001853\n",
      "2019-10-01 12:30:40.191482: step 354000/455000 (epoch 55/70), loss = 0.747083 (0.306 sec/batch), lr: 0.001853\n",
      "2019-10-01 12:37:58.036736: step 355000/455000 (epoch 55/70), loss = 0.598801 (0.557 sec/batch), lr: 0.001853\n",
      "2019-10-01 12:45:21.087440: step 356000/455000 (epoch 55/70), loss = 0.716812 (0.318 sec/batch), lr: 0.001853\n",
      "2019-10-01 12:52:45.658563: step 357000/455000 (epoch 55/70), loss = 0.588990 (0.433 sec/batch), lr: 0.001853\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.83      0.79     10000\n",
      "          1       0.61      0.62      0.61     10000\n",
      "          2       0.66      0.53      0.58     10000\n",
      "          3       0.60      0.58      0.59     10000\n",
      "          4       0.72      0.79      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.6686\n",
      "epoch 55: train_loss = 0.727845, dev_loss = 1.555566, dev_f1 = 0.6686\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_55.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 13:01:27.935978: step 358000/455000 (epoch 56/70), loss = 0.709050 (0.304 sec/batch), lr: 0.001853\n",
      "2019-10-01 13:08:48.454124: step 359000/455000 (epoch 56/70), loss = 0.648639 (0.399 sec/batch), lr: 0.001853\n",
      "2019-10-01 13:16:10.486953: step 360000/455000 (epoch 56/70), loss = 0.780405 (0.354 sec/batch), lr: 0.001853\n",
      "2019-10-01 13:23:30.883316: step 361000/455000 (epoch 56/70), loss = 0.702912 (0.435 sec/batch), lr: 0.001853\n",
      "2019-10-01 13:30:50.026235: step 362000/455000 (epoch 56/70), loss = 0.773584 (0.297 sec/batch), lr: 0.001853\n",
      "2019-10-01 13:38:13.696596: step 363000/455000 (epoch 56/70), loss = 0.692073 (0.550 sec/batch), lr: 0.001853\n",
      "2019-10-01 13:45:38.235802: step 364000/455000 (epoch 56/70), loss = 0.792487 (0.319 sec/batch), lr: 0.001853\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.83      0.78     10000\n",
      "          1       0.61      0.62      0.61     10000\n",
      "          2       0.66      0.53      0.59     10000\n",
      "          3       0.61      0.55      0.58     10000\n",
      "          4       0.71      0.80      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.66834\n",
      "epoch 56: train_loss = 0.727493, dev_loss = 1.561125, dev_f1 = 0.6683\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_56.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 13:54:17.998575: step 365000/455000 (epoch 57/70), loss = 0.782758 (0.441 sec/batch), lr: 0.001668\n",
      "2019-10-01 14:01:39.748119: step 366000/455000 (epoch 57/70), loss = 0.600600 (0.469 sec/batch), lr: 0.001668\n",
      "2019-10-01 14:09:01.373749: step 367000/455000 (epoch 57/70), loss = 0.740906 (0.307 sec/batch), lr: 0.001668\n",
      "2019-10-01 14:16:18.810866: step 368000/455000 (epoch 57/70), loss = 0.595666 (0.555 sec/batch), lr: 0.001668\n",
      "2019-10-01 14:23:41.919229: step 369000/455000 (epoch 57/70), loss = 0.753716 (0.316 sec/batch), lr: 0.001668\n",
      "2019-10-01 14:31:06.527428: step 370000/455000 (epoch 57/70), loss = 0.565304 (0.438 sec/batch), lr: 0.001668\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.83      0.79     10000\n",
      "          1       0.61      0.62      0.62     10000\n",
      "          2       0.66      0.53      0.59     10000\n",
      "          3       0.61      0.55      0.58     10000\n",
      "          4       0.70      0.81      0.75     10000\n",
      "\n",
      "avg / total       0.67      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.66928\n",
      "epoch 57: train_loss = 0.725383, dev_loss = 1.562283, dev_f1 = 0.6693\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_57.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 14:39:48.657157: step 371000/455000 (epoch 58/70), loss = 0.687253 (0.302 sec/batch), lr: 0.001668\n",
      "2019-10-01 14:47:09.386488: step 372000/455000 (epoch 58/70), loss = 0.667871 (0.401 sec/batch), lr: 0.001668\n",
      "2019-10-01 14:54:31.441032: step 373000/455000 (epoch 58/70), loss = 0.822729 (0.353 sec/batch), lr: 0.001668\n",
      "2019-10-01 15:01:51.625082: step 374000/455000 (epoch 58/70), loss = 0.731845 (0.438 sec/batch), lr: 0.001668\n",
      "2019-10-01 15:09:10.591504: step 375000/455000 (epoch 58/70), loss = 0.844488 (0.296 sec/batch), lr: 0.001668\n",
      "2019-10-01 15:16:33.972214: step 376000/455000 (epoch 58/70), loss = 0.620217 (0.554 sec/batch), lr: 0.001668\n",
      "2019-10-01 15:23:58.207264: step 377000/455000 (epoch 58/70), loss = 0.722941 (0.322 sec/batch), lr: 0.001668\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.82      0.78     10000\n",
      "          1       0.61      0.63      0.62     10000\n",
      "          2       0.65      0.53      0.59     10000\n",
      "          3       0.61      0.55      0.58     10000\n",
      "          4       0.71      0.81      0.75     10000\n",
      "\n",
      "avg / total       0.66      0.67      0.66     50000\n",
      "\n",
      "accuracy: 0.6687\n",
      "epoch 58: train_loss = 0.724945, dev_loss = 1.549646, dev_f1 = 0.6687\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_58.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 15:32:37.439334: step 378000/455000 (epoch 59/70), loss = 0.767956 (0.438 sec/batch), lr: 0.001501\n",
      "2019-10-01 15:39:59.057909: step 379000/455000 (epoch 59/70), loss = 0.698035 (0.473 sec/batch), lr: 0.001501\n",
      "2019-10-01 15:47:20.597637: step 380000/455000 (epoch 59/70), loss = 0.653456 (0.306 sec/batch), lr: 0.001501\n",
      "2019-10-01 15:54:37.795500: step 381000/455000 (epoch 59/70), loss = 0.598581 (0.556 sec/batch), lr: 0.001501\n",
      "2019-10-01 16:02:00.403532: step 382000/455000 (epoch 59/70), loss = 0.741470 (0.316 sec/batch), lr: 0.001501\n",
      "2019-10-01 16:09:24.634610: step 383000/455000 (epoch 59/70), loss = 0.589814 (0.433 sec/batch), lr: 0.001501\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.82      0.79     10000\n",
      "          1       0.61      0.63      0.62     10000\n",
      "          2       0.65      0.54      0.59     10000\n",
      "          3       0.60      0.57      0.59     10000\n",
      "          4       0.72      0.79      0.75     10000\n",
      "\n",
      "avg / total       0.67      0.67      0.67     50000\n",
      "\n",
      "accuracy: 0.671\n",
      "epoch 59: train_loss = 0.723487, dev_loss = 1.540551, dev_f1 = 0.6710\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_59.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 16:18:08.661679: step 384000/455000 (epoch 60/70), loss = 0.739930 (0.302 sec/batch), lr: 0.001501\n",
      "2019-10-01 16:25:28.995694: step 385000/455000 (epoch 60/70), loss = 0.680635 (0.401 sec/batch), lr: 0.001501\n",
      "2019-10-01 16:32:50.949075: step 386000/455000 (epoch 60/70), loss = 0.819716 (0.348 sec/batch), lr: 0.001501\n",
      "2019-10-01 16:40:11.227154: step 387000/455000 (epoch 60/70), loss = 0.703943 (0.435 sec/batch), lr: 0.001501\n",
      "2019-10-01 16:47:30.114816: step 388000/455000 (epoch 60/70), loss = 0.833551 (0.297 sec/batch), lr: 0.001501\n",
      "2019-10-01 16:54:53.466977: step 389000/455000 (epoch 60/70), loss = 0.661292 (0.551 sec/batch), lr: 0.001501\n",
      "2019-10-01 17:02:17.471448: step 390000/455000 (epoch 60/70), loss = 0.695938 (0.320 sec/batch), lr: 0.001501\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.82      0.79     10000\n",
      "          1       0.61      0.62      0.62     10000\n",
      "          2       0.66      0.53      0.59     10000\n",
      "          3       0.59      0.59      0.59     10000\n",
      "          4       0.72      0.79      0.75     10000\n",
      "\n",
      "avg / total       0.67      0.67      0.67     50000\n",
      "\n",
      "accuracy: 0.67068\n",
      "epoch 60: train_loss = 0.723725, dev_loss = 1.552503, dev_f1 = 0.6707\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_60.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 17:10:56.784078: step 391000/455000 (epoch 61/70), loss = 0.761280 (0.440 sec/batch), lr: 0.001351\n",
      "2019-10-01 17:18:17.915542: step 392000/455000 (epoch 61/70), loss = 0.652964 (0.469 sec/batch), lr: 0.001351\n",
      "2019-10-01 17:25:39.017100: step 393000/455000 (epoch 61/70), loss = 0.710772 (0.308 sec/batch), lr: 0.001351\n",
      "2019-10-01 17:32:56.045426: step 394000/455000 (epoch 61/70), loss = 0.625481 (0.554 sec/batch), lr: 0.001351\n",
      "2019-10-01 17:40:18.877467: step 395000/455000 (epoch 61/70), loss = 0.715150 (0.318 sec/batch), lr: 0.001351\n",
      "2019-10-01 17:47:43.409619: step 396000/455000 (epoch 61/70), loss = 0.582485 (0.433 sec/batch), lr: 0.001351\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.83      0.79     10000\n",
      "          1       0.61      0.63      0.62     10000\n",
      "          2       0.66      0.54      0.59     10000\n",
      "          3       0.61      0.56      0.58     10000\n",
      "          4       0.71      0.80      0.75     10000\n",
      "\n",
      "avg / total       0.67      0.67      0.67     50000\n",
      "\n",
      "accuracy: 0.66984\n",
      "epoch 61: train_loss = 0.721420, dev_loss = 1.548595, dev_f1 = 0.6698\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_61.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 17:56:25.849969: step 397000/455000 (epoch 62/70), loss = 0.675974 (0.302 sec/batch), lr: 0.001216\n",
      "2019-10-01 18:03:46.332847: step 398000/455000 (epoch 62/70), loss = 0.626908 (0.399 sec/batch), lr: 0.001216\n",
      "2019-10-01 18:11:08.144519: step 399000/455000 (epoch 62/70), loss = 0.801688 (0.349 sec/batch), lr: 0.001216\n",
      "2019-10-01 18:18:27.924087: step 400000/455000 (epoch 62/70), loss = 0.668658 (0.437 sec/batch), lr: 0.001216\n",
      "2019-10-01 18:25:46.693985: step 401000/455000 (epoch 62/70), loss = 0.867029 (0.298 sec/batch), lr: 0.001216\n",
      "2019-10-01 18:33:10.041112: step 402000/455000 (epoch 62/70), loss = 0.653215 (0.550 sec/batch), lr: 0.001216\n",
      "2019-10-01 18:40:34.185411: step 403000/455000 (epoch 62/70), loss = 0.695738 (0.321 sec/batch), lr: 0.001216\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.82      0.79     10000\n",
      "          1       0.62      0.62      0.62     10000\n",
      "          2       0.65      0.55      0.60     10000\n",
      "          3       0.60      0.55      0.58     10000\n",
      "          4       0.71      0.81      0.75     10000\n",
      "\n",
      "avg / total       0.67      0.67      0.67     50000\n",
      "\n",
      "accuracy: 0.66994\n",
      "epoch 62: train_loss = 0.720560, dev_loss = 1.550118, dev_f1 = 0.6699\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_62.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 18:49:13.706643: step 404000/455000 (epoch 63/70), loss = 0.778237 (0.441 sec/batch), lr: 0.001216\n",
      "2019-10-01 18:56:34.949986: step 405000/455000 (epoch 63/70), loss = 0.657376 (0.469 sec/batch), lr: 0.001216\n",
      "2019-10-01 19:03:56.366012: step 406000/455000 (epoch 63/70), loss = 0.723191 (0.309 sec/batch), lr: 0.001216\n",
      "2019-10-01 19:11:13.751366: step 407000/455000 (epoch 63/70), loss = 0.603051 (0.555 sec/batch), lr: 0.001216\n",
      "2019-10-01 19:18:36.799253: step 408000/455000 (epoch 63/70), loss = 0.715901 (0.319 sec/batch), lr: 0.001216\n",
      "2019-10-01 19:26:01.317874: step 409000/455000 (epoch 63/70), loss = 0.578568 (0.431 sec/batch), lr: 0.001216\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.82      0.79     10000\n",
      "          1       0.61      0.63      0.62     10000\n",
      "          2       0.65      0.54      0.59     10000\n",
      "          3       0.60      0.56      0.58     10000\n",
      "          4       0.72      0.79      0.75     10000\n",
      "\n",
      "avg / total       0.67      0.67      0.67     50000\n",
      "\n",
      "accuracy: 0.66968\n",
      "epoch 63: train_loss = 0.720487, dev_loss = 1.550948, dev_f1 = 0.6697\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_63.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 19:34:43.821590: step 410000/455000 (epoch 64/70), loss = 0.703156 (0.303 sec/batch), lr: 0.001094\n",
      "2019-10-01 19:42:04.511804: step 411000/455000 (epoch 64/70), loss = 0.588383 (0.400 sec/batch), lr: 0.001094\n",
      "2019-10-01 19:49:26.869759: step 412000/455000 (epoch 64/70), loss = 0.754359 (0.353 sec/batch), lr: 0.001094\n",
      "2019-10-01 19:56:47.753826: step 413000/455000 (epoch 64/70), loss = 0.724680 (0.440 sec/batch), lr: 0.001094\n",
      "2019-10-01 20:04:06.809734: step 414000/455000 (epoch 64/70), loss = 0.891624 (0.299 sec/batch), lr: 0.001094\n",
      "2019-10-01 20:11:30.157851: step 415000/455000 (epoch 64/70), loss = 0.588396 (0.555 sec/batch), lr: 0.001094\n",
      "2019-10-01 20:18:54.360691: step 416000/455000 (epoch 64/70), loss = 0.691836 (0.320 sec/batch), lr: 0.001094\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.76      0.82      0.79     10000\n",
      "          1       0.61      0.63      0.62     10000\n",
      "          2       0.65      0.56      0.60     10000\n",
      "          3       0.61      0.56      0.58     10000\n",
      "          4       0.71      0.80      0.75     10000\n",
      "\n",
      "avg / total       0.67      0.67      0.67     50000\n",
      "\n",
      "accuracy: 0.67164\n",
      "epoch 64: train_loss = 0.719369, dev_loss = 1.539400, dev_f1 = 0.6716\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_64.pt\n",
      "new best model saved.\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 20:27:35.485397: step 417000/455000 (epoch 65/70), loss = 0.806731 (0.439 sec/batch), lr: 0.001094\n",
      "2019-10-01 20:34:57.049411: step 418000/455000 (epoch 65/70), loss = 0.630052 (0.469 sec/batch), lr: 0.001094\n",
      "2019-10-01 20:42:18.321606: step 419000/455000 (epoch 65/70), loss = 0.667237 (0.306 sec/batch), lr: 0.001094\n",
      "2019-10-01 20:49:35.345010: step 420000/455000 (epoch 65/70), loss = 0.640196 (0.556 sec/batch), lr: 0.001094\n",
      "2019-10-01 20:56:58.149934: step 421000/455000 (epoch 65/70), loss = 0.751214 (0.320 sec/batch), lr: 0.001094\n",
      "2019-10-01 21:04:22.436543: step 422000/455000 (epoch 65/70), loss = 0.582952 (0.434 sec/batch), lr: 0.001094\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.83      0.79     10000\n",
      "          1       0.62      0.62      0.62     10000\n",
      "          2       0.65      0.56      0.60     10000\n",
      "          3       0.61      0.56      0.58     10000\n",
      "          4       0.72      0.79      0.75     10000\n",
      "\n",
      "avg / total       0.67      0.67      0.67     50000\n",
      "\n",
      "accuracy: 0.67132\n",
      "epoch 65: train_loss = 0.718483, dev_loss = 1.553891, dev_f1 = 0.6713\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_65.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 21:13:03.896379: step 423000/455000 (epoch 66/70), loss = 0.711432 (0.303 sec/batch), lr: 0.000985\n",
      "2019-10-01 21:20:23.972967: step 424000/455000 (epoch 66/70), loss = 0.646009 (0.403 sec/batch), lr: 0.000985\n",
      "2019-10-01 21:27:45.609990: step 425000/455000 (epoch 66/70), loss = 0.796292 (0.350 sec/batch), lr: 0.000985\n",
      "2019-10-01 21:35:05.640951: step 426000/455000 (epoch 66/70), loss = 0.678668 (0.439 sec/batch), lr: 0.000985\n",
      "2019-10-01 21:42:24.803205: step 427000/455000 (epoch 66/70), loss = 0.916083 (0.297 sec/batch), lr: 0.000985\n",
      "2019-10-01 21:49:48.268796: step 428000/455000 (epoch 66/70), loss = 0.686803 (0.551 sec/batch), lr: 0.000985\n",
      "2019-10-01 21:57:12.754291: step 429000/455000 (epoch 66/70), loss = 0.715880 (0.320 sec/batch), lr: 0.000985\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.82      0.79     10000\n",
      "          1       0.61      0.62      0.62     10000\n",
      "          2       0.65      0.55      0.60     10000\n",
      "          3       0.60      0.56      0.58     10000\n",
      "          4       0.71      0.79      0.75     10000\n",
      "\n",
      "avg / total       0.67      0.67      0.67     50000\n",
      "\n",
      "accuracy: 0.67072\n",
      "epoch 66: train_loss = 0.717659, dev_loss = 1.543860, dev_f1 = 0.6707\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_66.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 22:05:52.144605: step 430000/455000 (epoch 67/70), loss = 0.880855 (0.440 sec/batch), lr: 0.000886\n",
      "2019-10-01 22:13:13.648512: step 431000/455000 (epoch 67/70), loss = 0.653393 (0.470 sec/batch), lr: 0.000886\n",
      "2019-10-01 22:20:35.084581: step 432000/455000 (epoch 67/70), loss = 0.684413 (0.308 sec/batch), lr: 0.000886\n",
      "2019-10-01 22:27:52.274905: step 433000/455000 (epoch 67/70), loss = 0.599273 (0.556 sec/batch), lr: 0.000886\n",
      "2019-10-01 22:35:15.128820: step 434000/455000 (epoch 67/70), loss = 0.771448 (0.315 sec/batch), lr: 0.000886\n",
      "2019-10-01 22:42:39.505876: step 435000/455000 (epoch 67/70), loss = 0.559072 (0.433 sec/batch), lr: 0.000886\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.83      0.79     10000\n",
      "          1       0.62      0.61      0.61     10000\n",
      "          2       0.65      0.56      0.60     10000\n",
      "          3       0.60      0.57      0.58     10000\n",
      "          4       0.71      0.80      0.75     10000\n",
      "\n",
      "avg / total       0.67      0.67      0.67     50000\n",
      "\n",
      "accuracy: 0.67146\n",
      "epoch 67: train_loss = 0.717006, dev_loss = 1.544233, dev_f1 = 0.6715\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_67.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 22:51:21.865635: step 436000/455000 (epoch 68/70), loss = 0.667420 (0.304 sec/batch), lr: 0.000886\n",
      "2019-10-01 22:58:42.473427: step 437000/455000 (epoch 68/70), loss = 0.662194 (0.400 sec/batch), lr: 0.000886\n",
      "2019-10-01 23:06:04.566847: step 438000/455000 (epoch 68/70), loss = 0.822149 (0.351 sec/batch), lr: 0.000886\n",
      "2019-10-01 23:13:24.696629: step 439000/455000 (epoch 68/70), loss = 0.681220 (0.437 sec/batch), lr: 0.000886\n",
      "2019-10-01 23:20:43.543939: step 440000/455000 (epoch 68/70), loss = 0.860772 (0.297 sec/batch), lr: 0.000886\n",
      "2019-10-01 23:28:06.800674: step 441000/455000 (epoch 68/70), loss = 0.663594 (0.550 sec/batch), lr: 0.000886\n",
      "2019-10-01 23:35:31.013446: step 442000/455000 (epoch 68/70), loss = 0.751178 (0.321 sec/batch), lr: 0.000886\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.74      0.83      0.79     10000\n",
      "          1       0.62      0.61      0.61     10000\n",
      "          2       0.65      0.55      0.60     10000\n",
      "          3       0.60      0.55      0.58     10000\n",
      "          4       0.71      0.80      0.75     10000\n",
      "\n",
      "avg / total       0.67      0.67      0.67     50000\n",
      "\n",
      "accuracy: 0.6698\n",
      "epoch 68: train_loss = 0.716609, dev_loss = 1.554496, dev_f1 = 0.6698\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_68.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-01 23:44:10.191367: step 443000/455000 (epoch 69/70), loss = 0.785174 (0.440 sec/batch), lr: 0.000798\n",
      "2019-10-01 23:51:31.600682: step 444000/455000 (epoch 69/70), loss = 0.657336 (0.466 sec/batch), lr: 0.000798\n",
      "2019-10-01 23:58:53.027570: step 445000/455000 (epoch 69/70), loss = 0.684250 (0.308 sec/batch), lr: 0.000798\n",
      "2019-10-02 00:06:10.313068: step 446000/455000 (epoch 69/70), loss = 0.692613 (0.557 sec/batch), lr: 0.000798\n",
      "2019-10-02 00:13:33.284754: step 447000/455000 (epoch 69/70), loss = 0.825855 (0.317 sec/batch), lr: 0.000798\n",
      "2019-10-02 00:20:57.744569: step 448000/455000 (epoch 69/70), loss = 0.583533 (0.435 sec/batch), lr: 0.000798\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.82      0.79     10000\n",
      "          1       0.62      0.62      0.62     10000\n",
      "          2       0.65      0.57      0.60     10000\n",
      "          3       0.61      0.56      0.58     10000\n",
      "          4       0.71      0.79      0.75     10000\n",
      "\n",
      "avg / total       0.67      0.67      0.67     50000\n",
      "\n",
      "accuracy: 0.6716\n",
      "epoch 69: train_loss = 0.715685, dev_loss = 1.547645, dev_f1 = 0.6716\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_69.pt\n",
      "\n",
      "Current params:  heads-6 enc_layers-1  drop-0.4 scaled_drop-0.1 lr-0.01  lr_decay-0.9 max_grad_norm-1.0\n",
      " weight_no_rel-1.0 weight_rest-1.0 attn-True attn_dim-200  obj_sub_pos-False new_residual-False\n",
      " use_batch_norm-False relative_positions-True  decay_epoch-10 use_lemmas-False  hidden_self-130\n",
      "2019-10-02 00:29:39.833596: step 449000/455000 (epoch 70/70), loss = 0.720971 (0.302 sec/batch), lr: 0.000798\n",
      "2019-10-02 00:37:00.399466: step 450000/455000 (epoch 70/70), loss = 0.619301 (0.400 sec/batch), lr: 0.000798\n",
      "2019-10-02 00:44:22.517734: step 451000/455000 (epoch 70/70), loss = 0.772105 (0.353 sec/batch), lr: 0.000798\n",
      "2019-10-02 00:51:42.818469: step 452000/455000 (epoch 70/70), loss = 0.685642 (0.437 sec/batch), lr: 0.000798\n",
      "2019-10-02 00:59:02.255489: step 453000/455000 (epoch 70/70), loss = 0.803337 (0.300 sec/batch), lr: 0.000798\n",
      "2019-10-02 01:06:25.973336: step 454000/455000 (epoch 70/70), loss = 0.678716 (0.550 sec/batch), lr: 0.000798\n",
      "2019-10-02 01:13:50.618544: step 455000/455000 (epoch 70/70), loss = 0.749447 (0.320 sec/batch), lr: 0.000798\n",
      "Evaluating on dev set...\n",
      "             precision    recall  f1-score   support\n",
      "\n",
      "          0       0.75      0.82      0.79     10000\n",
      "          1       0.62      0.62      0.62     10000\n",
      "          2       0.64      0.56      0.60     10000\n",
      "          3       0.60      0.57      0.58     10000\n",
      "          4       0.72      0.79      0.75     10000\n",
      "\n",
      "avg / total       0.67      0.67      0.67     50000\n",
      "\n",
      "accuracy: 0.67094\n",
      "epoch 70: train_loss = 0.715747, dev_loss = 1.549947, dev_f1 = 0.6709\n",
      "model saved to ./saved_models/tmp_model/checkpoint_epoch_70.pt\n",
      "\n",
      "Training ended with 70 epochs.\n"
     ]
    }
   ],
   "source": [
    "# setup the scheduler for lr decay\n",
    "# this doesn't seem to work well compared to what we already have\n",
    "# scheduler = ReduceLROnPlateau(model.optimizer, mode='min', factor=opt['lr_decay'], patience=1)\n",
    "\n",
    "# start training\n",
    "for epoch in range(1, opt['num_epoch']+1):\n",
    "\n",
    "    print(\n",
    "        \"Current params: \" + \" heads-\" + str(opt[\"n_head\"]) + \" enc_layers-\" + str(opt[\"num_layers_encoder\"]),\n",
    "        \" drop-\" + str(opt[\"dropout\"]) + \" scaled_drop-\" + str(opt[\"scaled_dropout\"]) + \" lr-\" + str(opt[\"lr\"]),\n",
    "        \" lr_decay-\" + str(opt[\"lr_decay\"]) + \" max_grad_norm-\" + str(opt[\"max_grad_norm\"])\n",
    "    )\n",
    "    print(\n",
    "        \" attn-\" + str(opt[\"attn\"]) + \" attn_dim-\" + str(opt[\"attn_dim\"]),\n",
    "        \" new_residual-\" + str(opt[\"new_residual\"])\n",
    "    )\n",
    "    print(\n",
    "        \" use_batch_norm-\"+str(opt[\"use_batch_norm\"]) + \" relative_positions-\"+str(opt[\"relative_positions\"]),\n",
    "        \" decay_epoch-\"+str(opt[\"decay_epoch\"]) + \" use_lemmas-\"+str(opt[\"use_lemmas\"]),\n",
    "        \" hidden_self-\"+str(opt[\"hidden_self\"])\n",
    "    )\n",
    "\n",
    "    train_loss = 0\n",
    "    for i, batch in enumerate(train_batch):\n",
    "\n",
    "        start_time = time.time()\n",
    "        global_step += 1\n",
    "\n",
    "        loss = model.update(batch)\n",
    "        train_loss += float(loss)\n",
    "\n",
    "        if global_step % opt['log_step'] == 0:\n",
    "            duration = time.time() - start_time\n",
    "            print(\n",
    "                format_str.format(datetime.now(), global_step, max_steps, epoch,\n",
    "                opt['num_epoch'], loss, duration, current_lr)\n",
    "            )\n",
    "        # do garbage collection,\n",
    "        # as per https://discuss.pytorch.org/t/best-practices-for-maximum-gpu-utilization/13863/6\n",
    "        del loss\n",
    "\n",
    "    # eval on dev\n",
    "    print(\"Evaluating on dev set...\")\n",
    "    predictions = []\n",
    "    dev_loss = 0\n",
    "    for i, batch in enumerate(dev_batch):\n",
    "        preds, _, loss,_ = model.predict(batch)\n",
    "        predictions += preds\n",
    "        dev_loss += float(loss)\n",
    "        del loss\n",
    "\n",
    "    print(classification_report(dev_batch.gold(), predictions))\n",
    "    dev_f1 = accuracy_score(dev_batch.gold(), predictions)\n",
    "    print('accuracy:',dev_f1)\n",
    "\n",
    "    train_loss = train_loss / train_batch.num_examples * opt['batch_size'] # avg loss per batch\n",
    "    dev_loss = dev_loss / dev_batch.num_examples * opt['batch_size']\n",
    "    print(\n",
    "        \"epoch {}: train_loss = {:.6f}, dev_loss = {:.6f}, dev_f1 = {:.4f}\".format(epoch,\\\n",
    "            train_loss, dev_loss, dev_f1)\n",
    "        )\n",
    "#     file_logger.log(\"{}\\t{:.6f}\\t{:.6f}\\t{:.4f}\\t{:.4f}\\t{:.4f}\".format(\n",
    "#         epoch, train_loss, dev_loss, dev_p, dev_r, dev_f1)\n",
    "#     )\n",
    "\n",
    "#     # save\n",
    "#     model_file = model_save_dir + '/checkpoint_epoch_{}.pt'.format(epoch)\n",
    "#     model.save(model_file, epoch)\n",
    "#     if epoch == 1 or dev_f1 > max(dev_f1_history):\n",
    "#         copyfile(model_file, model_save_dir + '/best_model.pt')\n",
    "#         print(\"new best model saved.\")\n",
    "#     if epoch % opt['save_epoch'] != 0:\n",
    "#         os.remove(model_file)\n",
    "\n",
    "    # reduce learning rate if it stagnates by a certain decay rate and within given epoch patience\n",
    "    # this for some reason works worth than the implementation we have afterwards\n",
    "    # scheduler.step(dev_loss)\n",
    "\n",
    "    if opt[\"optim\"] != \"noopt_adam\" and opt[\"optim\"] != \"noopt_nadam\":\n",
    "\n",
    "        # do warm_up_for sgd only instead of adam\n",
    "        do_warmup_trick = False\n",
    "\n",
    "        if not do_warmup_trick:\n",
    "            # decay schedule # 15 is best!\n",
    "            # simulate patience of x epochs\n",
    "            if len(dev_f1_history) > opt['decay_epoch'] and dev_f1 <= dev_f1_history[-1]:\n",
    "                current_lr *= opt['lr_decay']\n",
    "                model.update_lr(current_lr)\n",
    "        else:\n",
    "            # print(\"do_warmup_trick\")\n",
    "            # 1 and 5 first worked kind of\n",
    "            # 10 and 15\n",
    "            current_lr = 10 * (360 ** (-0.5) * min(epoch ** (-0.5), epoch * 15 ** (-1.5)))\n",
    "            print(\"current_lr\", current_lr)\n",
    "            model.update_lr(current_lr)\n",
    "    # else, update the learning rate in torch_utils.py\n",
    "\n",
    "    dev_f1_history += [dev_f1]\n",
    "    print(\"\")\n",
    "\n",
    "print(\"Training ended with {} epochs.\".format(epoch))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "64\n",
      "0.67164\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[0.577,\n",
       " 0.59698,\n",
       " 0.61206,\n",
       " 0.6144,\n",
       " 0.61594,\n",
       " 0.62218,\n",
       " 0.62954,\n",
       " 0.63412,\n",
       " 0.63878,\n",
       " 0.63834,\n",
       " 0.63826,\n",
       " 0.6422,\n",
       " 0.64044,\n",
       " 0.64792,\n",
       " 0.6457,\n",
       " 0.64996,\n",
       " 0.64882,\n",
       " 0.6519,\n",
       " 0.65096,\n",
       " 0.65066,\n",
       " 0.65426,\n",
       " 0.65054,\n",
       " 0.65484,\n",
       " 0.65238,\n",
       " 0.65468,\n",
       " 0.65468,\n",
       " 0.6557,\n",
       " 0.65754,\n",
       " 0.65854,\n",
       " 0.65844,\n",
       " 0.6598,\n",
       " 0.65978,\n",
       " 0.66018,\n",
       " 0.65952,\n",
       " 0.66094,\n",
       " 0.66292,\n",
       " 0.66358,\n",
       " 0.6655,\n",
       " 0.6607,\n",
       " 0.66222,\n",
       " 0.66666,\n",
       " 0.6642,\n",
       " 0.666,\n",
       " 0.6672,\n",
       " 0.66906,\n",
       " 0.66526,\n",
       " 0.66664,\n",
       " 0.66752,\n",
       " 0.66804,\n",
       " 0.66814,\n",
       " 0.66682,\n",
       " 0.67012,\n",
       " 0.66782,\n",
       " 0.6683,\n",
       " 0.6686,\n",
       " 0.66834,\n",
       " 0.66928,\n",
       " 0.6687,\n",
       " 0.671,\n",
       " 0.67068,\n",
       " 0.66984,\n",
       " 0.66994,\n",
       " 0.66968,\n",
       " 0.67164,\n",
       " 0.67132,\n",
       " 0.67072,\n",
       " 0.67146,\n",
       " 0.6698,\n",
       " 0.6716,\n",
       " 0.67094]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print(np.argmax(dev_f1_history)+1)\n",
    "print(max(dev_f1_history))\n",
    "dev_f1_history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
